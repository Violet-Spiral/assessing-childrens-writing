{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF First Simple Model\n",
    "Logistic Regression out of the box, n-grams=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>grammarized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I had just gone to Chobot Space and Science Ce...</td>\n",
       "      <td>i have just go to chobot space and science cen...</td>\n",
       "      <td>I had just gone to + chobot + space and + scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>My cat is fluffy. His name is Buzz. He is my f...</td>\n",
       "      <td>my cat be fluffy his name be buzz he be my fav...</td>\n",
       "      <td>+ my cat is fluffy . + his name is + buzz . + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Spring is sweet because we can go boat riding ...</td>\n",
       "      <td>spring be sweet because we can go boat riding ...</td>\n",
       "      <td>+ spring is sweet because we can go boat ridin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>One day baby Josh came home. He was in a yello...</td>\n",
       "      <td>one day baby josh come home he be in a yellow ...</td>\n",
       "      <td>+ one day baby + josh came home . + he was in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>One time I went to Mexico. It was a blast! I m...</td>\n",
       "      <td>one time i go to mexico it be a blast i meet p...</td>\n",
       "      <td>+ one time I went to + mexico . + it was a bla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grade                                               Text  \\\n",
       "0    1.0  I had just gone to Chobot Space and Science Ce...   \n",
       "1    1.0  My cat is fluffy. His name is Buzz. He is my f...   \n",
       "2    1.0  Spring is sweet because we can go boat riding ...   \n",
       "3    1.0  One day baby Josh came home. He was in a yello...   \n",
       "4    1.0  One time I went to Mexico. It was a blast! I m...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  i have just go to chobot space and science cen...   \n",
       "1  my cat be fluffy his name be buzz he be my fav...   \n",
       "2  spring be sweet because we can go boat riding ...   \n",
       "3  one day baby josh come home he be in a yellow ...   \n",
       "4  one time i go to mexico it be a blast i meet p...   \n",
       "\n",
       "                                         grammarized  \n",
       "0  I had just gone to + chobot + space and + scie...  \n",
       "1  + my cat is fluffy . + his name is + buzz . + ...  \n",
       "2  + spring is sweet because we can go boat ridin...  \n",
       "3  + one day baby + josh came home . + he was in ...  \n",
       "4  + one time I went to + mexico . + it was a bla...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed_text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(model, scores, X_train, y_train, ngram_range=(1,3)):\n",
    "    for ngram in range(ngram_range[0],ngram_range[1]+1):\n",
    "        lr_count_pipe = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,ngram))),\n",
    "                                  ('logreg', model)])\n",
    "\n",
    "        lemma_scores = cross_val_score(lr_count_pipe, X_train['lemmatized'],y_train, cv=3, \n",
    "                                       scoring='neg_mean_absolute_error')\n",
    "        grammar_scores = cross_val_score(lr_count_pipe, X_train['grammarized'], y_train, cv=3, \n",
    "                                         scoring='neg_mean_absolute_error')\n",
    "        scores = scores.append({'model':type(model).__name__,\n",
    "                        'encoding':'Count Vectors',\n",
    "                        'ngram':ngram,\n",
    "                       'lemmas':-np.mean(lemma_scores),\n",
    "                      'grammar':-np.mean(grammar_scores)},\n",
    "                      ignore_index=True)\n",
    "\n",
    "        lr_tfidf_pipe = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(1,ngram))),\n",
    "                              ('logreg', model)])\n",
    "        lemma_scores = cross_val_score(lr_tfidf_pipe, X_train['lemmatized'],y_train, cv=3, \n",
    "                                       scoring='neg_mean_absolute_error')\n",
    "        grammar_scores = cross_val_score(lr_tfidf_pipe, X_train['grammarized'], y_train, cv=3, \n",
    "                                         scoring='neg_mean_absolute_error')\n",
    "\n",
    "        scores = scores.append({'model':type(model).__name__,\n",
    "                        'encoding':'TF-IDF Vectors',\n",
    "                        'ngram':ngram,\n",
    "                       'lemmas':-np.mean(lemma_scores),\n",
    "                      'grammar':-np.mean(grammar_scores)},\n",
    "                      ignore_index=True)\n",
    "        print('finished ngram', ngram)\n",
    "        \n",
    "    return scores\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['lemmatized', 'grammarized']]\n",
    "y = df.Grade\n",
    "## Split lemma train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=11)\n",
    "scores = pd.DataFrame(columns = ['model','encoding','lemmas','grammar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished ngram 1\n",
      "finished ngram 2\n",
      "finished ngram 3\n"
     ]
    }
   ],
   "source": [
    "scores = assess_model(LinearRegression(), scores, X_train, y_train, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished ngram 1\n",
      "finished ngram 2\n",
      "finished ngram 3\n"
     ]
    }
   ],
   "source": [
    "scores = assess_model(DecisionTreeRegressor(), scores, X_train, y_train, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished ngram 1\n",
      "finished ngram 2\n",
      "finished ngram 3\n"
     ]
    }
   ],
   "source": [
    "scores = assess_model(RandomForestRegressor(), scores, X_train, y_train, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>encoding</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>grammar</th>\n",
       "      <th>ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>1.327574</td>\n",
       "      <td>1.298095</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>1.333105</td>\n",
       "      <td>1.313914</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>1.344008</td>\n",
       "      <td>1.346999</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.370492</td>\n",
       "      <td>1.376917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.488141</td>\n",
       "      <td>1.453934</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.532441</td>\n",
       "      <td>1.544971</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.578731</td>\n",
       "      <td>1.627360</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.605158</td>\n",
       "      <td>1.610830</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>1.775669</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>1.800154</td>\n",
       "      <td>1.688735</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>1.853035</td>\n",
       "      <td>1.701389</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.896348</td>\n",
       "      <td>2.015432</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.908796</td>\n",
       "      <td>1.858333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>1.924351</td>\n",
       "      <td>1.963925</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>TF-IDF Vectors</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>1.812654</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>2.215486</td>\n",
       "      <td>2.131369</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>2.254511</td>\n",
       "      <td>2.159745</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Count Vectors</td>\n",
       "      <td>2.454878</td>\n",
       "      <td>2.333550</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model        encoding    lemmas   grammar  ngram\n",
       "12  RandomForestRegressor   Count Vectors  1.327574  1.298095    1.0\n",
       "16  RandomForestRegressor   Count Vectors  1.333105  1.313914    3.0\n",
       "14  RandomForestRegressor   Count Vectors  1.344008  1.346999    2.0\n",
       "1        LinearRegression  TF-IDF Vectors  1.370492  1.376917    1.0\n",
       "13  RandomForestRegressor  TF-IDF Vectors  1.488141  1.453934    1.0\n",
       "15  RandomForestRegressor  TF-IDF Vectors  1.532441  1.544971    2.0\n",
       "3        LinearRegression  TF-IDF Vectors  1.578731  1.627360    2.0\n",
       "17  RandomForestRegressor  TF-IDF Vectors  1.605158  1.610830    3.0\n",
       "8   DecisionTreeRegressor   Count Vectors  1.775669  1.718519    2.0\n",
       "10  DecisionTreeRegressor   Count Vectors  1.800154  1.688735    3.0\n",
       "6   DecisionTreeRegressor   Count Vectors  1.853035  1.701389    1.0\n",
       "7   DecisionTreeRegressor  TF-IDF Vectors  1.896348  2.015432    1.0\n",
       "9   DecisionTreeRegressor  TF-IDF Vectors  1.908796  1.858333    2.0\n",
       "5        LinearRegression  TF-IDF Vectors  1.924351  1.963925    3.0\n",
       "11  DecisionTreeRegressor  TF-IDF Vectors  2.016667  1.812654    3.0\n",
       "4        LinearRegression   Count Vectors  2.215486  2.131369    3.0\n",
       "2        LinearRegression   Count Vectors  2.254511  2.159745    2.0\n",
       "0        LinearRegression   Count Vectors  2.454878  2.333550    1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(by=['lemmas','grammar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "rf_count_pipe = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                      ('RFreg', model)])\n",
    "rf_count_pipe.fit(X_train['grammarized'], y_train)\n",
    "yhat = rf_count_pipe.predict(X_test['grammarized'])\n",
    "plt.hist(yhat - y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('RFreg', RandomForestRegressor())]),\n",
       "             param_grid=[{'RFreg__max_depth': [4, 6, None],\n",
       "                          'RFreg__n_estimators': [100, 200, 300]}],\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_count_pipe = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                      ('RFreg', model)])\n",
    "param_grid = [{'RFreg__n_estimators':[100,200,300],\n",
    "              'RFreg__max_depth':[4,6,None],\n",
    "              }]\n",
    "clf = GridSearchCV(rf_count_pipe,\n",
    "                  param_grid, scoring='neg_mean_absolute_error')\n",
    "clf.fit(X_train.grammarized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RFreg__max_depth': None, 'RFreg__n_estimators': 300}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('RFreg', RandomForestRegressor())]),\n",
       "             param_grid=[{'RFreg__max_depth': [None],\n",
       "                          'RFreg__n_estimators': [300, 400, 500]}],\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_count_pipe = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                      ('RFreg', model)])\n",
    "param_grid = [{'RFreg__n_estimators':[300,400,500],\n",
    "              'RFreg__max_depth':[None],\n",
    "              }]\n",
    "clf = GridSearchCV(rf_count_pipe,\n",
    "                  param_grid, scoring='neg_mean_absolute_error')\n",
    "clf.fit(X_train.grammarized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2663993197278913\n",
      "{'RFreg__max_depth': None, 'RFreg__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('RFreg', RandomForestRegressor())]),\n",
       "             param_grid=[{'RFreg__max_depth': [None],\n",
       "                          'RFreg__n_estimators': [500, 1000]}],\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_count_pipe = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                      ('RFreg', model)])\n",
    "param_grid = [{'RFreg__n_estimators':[500,1000],\n",
    "              'RFreg__max_depth':[None],\n",
    "              }]\n",
    "clf = GridSearchCV(rf_count_pipe,\n",
    "                  param_grid, scoring='neg_mean_absolute_error')\n",
    "clf.fit(X_train.grammarized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2636130952380953\n",
      "{'RFreg__max_depth': None, 'RFreg__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45313664596273306\n"
     ]
    }
   ],
   "source": [
    "model = clf.best_estimator_\n",
    "model.fit(df.grammarized, df.Grade)\n",
    "yhat = model.predict(df['grammarized'])\n",
    "print(np.abs(df.Grade - yhat).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('RFreg', RandomForestRegressor(n_estimators=500))])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(model, open('best_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.128])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open('best_model.pkl','rb'))\n",
    "model.predict([df.grammarized[45]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Grade[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
