{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "report_notebook-text-experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QF0aa5kOYCQ",
        "scrolled": false,
        "outputId": "cbe43ead-ee8f-41da-efab-d0208c7fa72e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, \\\n",
        "Dropout, Activation, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers.experimental.preprocessing import TextVectorization\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.initializers import Constant\n",
        "\n",
        "\n",
        "# !pip install -q -U keras-tuner\n",
        "# import kerastuner as kt\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from src import load_text, predict_grade, separate_sentences, prepare_text\n",
        "\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import en_core_web_sm\n",
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows',50)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt21gZpf27Yy"
      },
      "source": [
        "# The Data\n",
        "the data consists of anonymized essays and stories written by students in grades kindergarten through high school.  We've collected these from around the web.  Let's look at some statistics below.\n",
        "\n",
        "## Alternative Grouping\n",
        "We removed samples from grades K (0) and 1 because we suspect most of them were dictated and transcribed by teachers.  They don't seem to be representative of independent writing skills.\n",
        "\n",
        "We also combined all high school grades to 12.  Previous iterations of the model did not do well distinguishing between high school level texts.  We changed them to 12 because later we want the model to use the average of sentences to predict the grade of a longer text.  The model will almost never predict 12 because an average will always bring it down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC8ByZYxw04W"
      },
      "source": [
        "lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvdeT6rgEIPq",
        "scrolled": false
      },
      "source": [
        "sp = en_core_web_sm.load()\n",
        "full_df = load_text()\n",
        "\n",
        "\n",
        "col = 'Grammar'\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEKkL8Vq6UDZ",
        "scrolled": false
      },
      "source": [
        "df = full_df[full_df.Grade > 1]\n",
        "\n",
        "X = df.Text\n",
        "y = df.Grade\n",
        "\n",
        "train = pd.DataFrame(columns = ['Grade','Text'])\n",
        "test = pd.DataFrame(columns = ['Grade','Text'])\n",
        "\n",
        "train['Text'], test['Text'], train['Grade'], test['Grade'] = train_test_split(X, y, random_state=111)\n",
        "train = separate_sentences(train)\n",
        "train = prepare_text(train, sp)\n",
        "\n",
        "X_t, X_val, y_t, y_val = train_test_split(train.drop(columns = 'Grade'), train.Grade, random_state=111)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0KTl112RMKF"
      },
      "source": [
        "sns.barplot(x=df.Grade.unique(), y=df.Grade.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPMVHwXB27Y0"
      },
      "source": [
        "You can see above that we have a large imbalance in grades represented.  It's tempting to cluster grades together, but we want a tool that predicts with some specificity.  Here's a lesson from my teaching years, however:  Most kids don't write sentences on their own in Kindergarten.  Looking over our texts for Kindergarten and first grade, these seem to be dictated and transcribed by an adult.  \n",
        "\n",
        "In model development we also saw that high school texts are difficult to classify accurately as well.  For these reasons, we clump all high school and K-2nd grade together.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi0DsT4aqS85"
      },
      "source": [
        "fig, axes = plt.subplots(4,3, figsize = (13,13))\n",
        "axes=axes.ravel()\n",
        "grades = sorted(df.Grade.unique())\n",
        "for i, grade in enumerate(grades):\n",
        "    text = ' '.join([story for story in df.loc[df.Grade == grade, 'Text']])\n",
        "    axes[i].imshow(WordCloud(width=800, height=400).generate(text))\n",
        "    axes[i].set_title(f'Frequency of words in grade {int(grade)}')\n",
        "    axes[i].axis('off')\n",
        "fig.delaxes(axes[-1])\n",
        "plt.tight_layout()\n",
        "plt.savefig('word_clouds.png', dpi=200)\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLtpn_FvXct4"
      },
      "source": [
        "# FSM\n",
        "How accurate would we be if we just predict all samples will be the median grade of the training set?  This can be our baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnT7d3STW_Pv"
      },
      "source": [
        "FSM = np.array([y_t.median()] * len(y_val))\n",
        "FSM_MAE = np.sum(np.abs(y_val - FSM))/len(y_val)\n",
        "print('Baseline MAE is: ', FSM_MAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spkMsD2q27Y1"
      },
      "source": [
        "So, that means our model has to beat 2.5 MAE to have any predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPPhHYb927Y1"
      },
      "source": [
        "# TF-IDF Vectorization\n",
        "\n",
        "TF-IDF vectorization represents each word with a float representing its relative specificity to a given document.  The random forest model, however, is non-sequential.  It looks at each sentence as a collection of words.  Therefor the above power represents the opportunity to judge writing level purely by vocabulary used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVaNTI3X27Y1"
      },
      "source": [
        "I'd like to have longer input sequences after vectorizing and padding than my longest sentence.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju7dxD71Jeuv"
      },
      "source": [
        "Vectorizer = TextVectorization(output_mode='tf-idf', max_tokens=None)\n",
        "Vectorizer.adapt(X_t[col].to_numpy())\n",
        "print(col)\n",
        "\n",
        "X_t_tfidf = Vectorizer(X_t[col])\n",
        "X_val_tfidf = Vectorizer(X_val[col])\n",
        "    \n",
        "X_t_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImIMnZLWJsK5"
      },
      "source": [
        "Lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZBMMZh27Y2"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "Let's see how far we can get with the simplest of linear predictive models based on the vocabulary in the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_13f3_Y_27Y2"
      },
      "source": [
        "lr_reg = LinearRegression().fit(X_t_tfidf, y_t)\n",
        "yhat = lr_reg.predict(X_val_tfidf)\n",
        "mae = np.sum(np.abs(y_val - yhat))/len(y_val)\n",
        "print('Baseline MAE is: ', FSM_MAE)\n",
        "print('MAE for Linear Regression on TF-IDF vectors = ', mae)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80lRCtLN7zNM"
      },
      "source": [
        "The linear regression slightly beat predicting the median, but not by a lot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n832vpV76D3s"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qytidsBr6DNX"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "XGB_reg = XGBRegressor().fit(X_t_tfidf, y_t)\n",
        "yhat = XGB_reg.predict(X_val_tfidf)\n",
        "mae = np.sum(np.abs(y_val - yhat))/len(y_val)\n",
        "print('Baseline MAE is: ', FSM_MAE)\n",
        "print('MAE for XGBoost TF-IDF vectors = ', mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt_yDu7A7oWG"
      },
      "source": [
        "XGBoost did not seem to improve much."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlgpchaZ27Y3"
      },
      "source": [
        "\n",
        "## Shallow Model development opportunities:\n",
        "My goal in this project is to explore deep learning NLP approaches, so I did not spend a lot of time tuning the traditional models.  I include them more as reference and justification for models that require greater computational resources.\n",
        "\n",
        "Opportunities:\n",
        "\n",
        "1. Hyperparameter tuning of traditional models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udf1NYx627Y3"
      },
      "source": [
        "# Deep Models\n",
        "\n",
        "I wonder if a model that explores the grammar and semantic relationships between words within the student writing samples might have greater insight into stages of writing development?  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGtcMB7a27Y3"
      },
      "source": [
        "# TextVectorization\n",
        "\n",
        "We used TextVectorization as TF-IDF encoder above, but it can also be used as a Keras model layer.  I create a new TextVectorization object with appropriate sequence lengths for padding.  Each word will be encoded as an integer and sentences will be arrays of integers.\n",
        "\n",
        "# Word Embedding\n",
        "\n",
        "My first choice, in order to preserve some of the semantic relationships between the words I used word embeddings, rather than TF-IDF, to vectorize my texts.  This is a very different approach and, in fact, whereas in many other vectorization strategies each word is represented by a single number, word embeddings encode each word as a high dimensional vector array.  That means that a sentence becomes a 2D matrix.  \n",
        "\n",
        "We don't encode the texts as such yet, but we do need to create a reference matrix to translate word encodings to their matching embedding vector.  Now Keras provides trainable embedding layers that learn along with the other layers of your model.  They contain huge numbers of weights depending on the size of your vocabulary and embedding length.\n",
        "\n",
        "However, there are several libraries of pre-trained word embeddings that can be loaded.  I use the SpaCy NLP package to create a word embedding matrix as a 2D matrix.  The indices will be the keys and the matching row will be the embedding.  These integers match the encoding that the TextVectorization layer uses.\n",
        "\n",
        "This matrix can then be loaded in as the weights of a Keras Embedding layer.  Remember to set `trainable=False`. The model will use the Embedding layer to cross-reference each word in the sentence.  These embeddings will suggest word relationships and will be read in order by the next layer, the Long-Short Term Memory layer.\n",
        "\n",
        "Thanks to https://keras.io/examples/nlp/pretrained_word_embeddings/ and Kefei Mo https://towardsdatascience.com/hands-on-nlp-deep-learning-model-preparation-in-tensorflow-2-x-2e8c9f3c7633 for the below code to create the weights matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCsXQhjpQdSV",
        "scrolled": false
      },
      "source": [
        "# Establish sequence length.  Set here as the longest sentence in the training set.\n",
        "X_train = train[col]\n",
        "y_train = train.Grade\n",
        "longest_sentence = X_train.str.len().max()\n",
        "\n",
        "# Instantiate and fit the vectorizing layer.  \n",
        "# We can use this as a transformer, a vocabulary, and a layer in our model.\n",
        "Vectorizer = TextVectorization(output_sequence_length=longest_sentence, max_tokens=2000)\n",
        "Vectorizer.adapt(X_train.to_numpy())\n",
        "vocab = Vectorizer.get_vocabulary()\n",
        "\n",
        "\n",
        "#generate the embedding matrix\n",
        "num_tokens = len(vocab)\n",
        "embedding_dim = len(sp('The').vector)\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for i, word in enumerate(vocab[1:]):\n",
        "    embedding_matrix[i+1] = sp(word).vector\n",
        "\n",
        "#Load the embedding matrix as the weights matrix for the embedding layer and set trainable to False\n",
        "Embedding_layer=Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=Constant(embedding_matrix),\n",
        "    trainable=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxdVuImjQdSg"
      },
      "source": [
        "# Hybrid Bi-directional\n",
        "We are going to pull out all the guns here and use a bi-directional LSTM with that pre-trained SpaCy embedding layer.  We are going to throw that on top of a deep densely connected network with a global max pool layer between them.\n",
        "\n",
        "The data comes in at the input layer and to the vectorizing layer which translates them into uniform length integer arrays.  Those arrays are are expanded into a 2D matrix in the Embedding layer.  The LSTM layer then reads the embeddings in the order they originally appeared in the text and makes choices about them.  This is a learned skill.  The bidirectional wrapper sends the text embedding both forward and backward through the layer and concatenates the output sequences together.  The GlobalMaxPooling1D layer reduces the dimensionality back down to pass to the densely connected layers.\n",
        "\n",
        "The model then outputs a float which represents its guess at the grade level of the author of a text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xI5CZok4S043",
        "scrolled": true,
        "outputId": "c8c9f0de-0079-4289-e291-ee423541efd8"
      },
      "source": [
        "filepath = 'model-BiLSTM-MLP-hybrid-sm'\n",
        "def make_BiLSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(1,), dtype=tf.string))\n",
        "    model.add(Vectorizer)\n",
        "    model.add(Embedding_layer)\n",
        "    model.add(Bidirectional(LSTM(50, return_sequences=False)))\n",
        "    # model.add(GlobalMaxPooling1D())\n",
        "    # model.add(Dropout(rate=0.3))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(rate=.1))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    sgd = SGD(learning_rate=.1, decay=1e-3)\n",
        "\n",
        "    model.compile(optimizer=sgd, loss='mean_absolute_error')\n",
        "    return model\n",
        "\n",
        "model = make_BiLSTM()\n",
        "print(model.summary())\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min',\n",
        "                             save_format='tf'\n",
        "                             )\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "history = model.fit(X_train,\n",
        "            y_train,\n",
        "            epochs=60,\n",
        "            batch_size=100,\n",
        "            validation_split = .2,\n",
        "            verbose=1,\n",
        "            callbacks=callbacks)\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization (TextVect (None, 1233)              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1233, 96)          192000    \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 100)               58800     \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 258,561\n",
            "Trainable params: 66,561\n",
            "Non-trainable params: 192,000\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/60\n",
            "63/63 [==============================] - 12s 146ms/step - loss: 4.3663 - val_loss: 2.7648\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.76476, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/60\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 2.6396 - val_loss: 2.4156\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.76476 to 2.41556, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/60\n",
            "63/63 [==============================] - 9s 136ms/step - loss: 2.5416 - val_loss: 2.3584\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.41556 to 2.35844, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/60\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 2.4953 - val_loss: 2.4539\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.35844\n",
            "Epoch 5/60\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 2.5402 - val_loss: 2.3412\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.35844 to 2.34118, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/60\n",
            "63/63 [==============================] - 8s 135ms/step - loss: 2.4850 - val_loss: 2.3643\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 2.34118\n",
            "Epoch 7/60\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 2.4724 - val_loss: 2.3186\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.34118 to 2.31856, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/60\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 2.4069 - val_loss: 2.2608\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.31856 to 2.26076, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/60\n",
            "63/63 [==============================] - 9s 135ms/step - loss: 2.4072 - val_loss: 2.2249\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.26076 to 2.22487, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/60\n",
            "63/63 [==============================] - 9s 135ms/step - loss: 2.3101 - val_loss: 2.1470\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.22487 to 2.14699, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/60\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 2.3056 - val_loss: 2.1355\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.14699 to 2.13547, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.2993 - val_loss: 2.2006\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.13547\n",
            "Epoch 13/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.2838 - val_loss: 2.2563\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.13547\n",
            "Epoch 14/60\n",
            "63/63 [==============================] - 9s 136ms/step - loss: 2.2598 - val_loss: 2.1524\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.13547\n",
            "Epoch 15/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.2066 - val_loss: 2.1328\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.13547 to 2.13279, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.2373 - val_loss: 2.1186\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.13279 to 2.11862, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.2088 - val_loss: 2.1236\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.11862\n",
            "Epoch 18/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.2127 - val_loss: 2.1474\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.11862\n",
            "Epoch 19/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.2079 - val_loss: 2.4198\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.11862\n",
            "Epoch 20/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.2302 - val_loss: 2.1661\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.11862\n",
            "Epoch 21/60\n",
            "63/63 [==============================] - 9s 140ms/step - loss: 2.2350 - val_loss: 2.1925\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.11862\n",
            "Epoch 22/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.1918 - val_loss: 2.1242\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 2.11862\n",
            "Epoch 23/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.1653 - val_loss: 2.1278\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 2.11862\n",
            "Epoch 24/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.1757 - val_loss: 2.0975\n",
            "\n",
            "Epoch 00024: val_loss improved from 2.11862 to 2.09753, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.1636 - val_loss: 2.0857\n",
            "\n",
            "Epoch 00025: val_loss improved from 2.09753 to 2.08565, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.1513 - val_loss: 2.0839\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.08565 to 2.08390, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 2.1156 - val_loss: 2.1403\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 2.08390\n",
            "Epoch 28/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.1640 - val_loss: 2.1977\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 2.08390\n",
            "Epoch 29/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.1434 - val_loss: 2.0957\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 2.08390\n",
            "Epoch 30/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 2.1216 - val_loss: 2.0875\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 2.08390\n",
            "Epoch 31/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.1105 - val_loss: 2.1368\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 2.08390\n",
            "Epoch 32/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0964 - val_loss: 2.0658\n",
            "\n",
            "Epoch 00032: val_loss improved from 2.08390 to 2.06578, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 2.1022 - val_loss: 2.1140\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 2.06578\n",
            "Epoch 34/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0282 - val_loss: 2.0800\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 2.06578\n",
            "Epoch 35/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.0618 - val_loss: 2.0971\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 2.06578\n",
            "Epoch 36/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0356 - val_loss: 2.2555\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 2.06578\n",
            "Epoch 37/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 2.0702 - val_loss: 2.0624\n",
            "\n",
            "Epoch 00037: val_loss improved from 2.06578 to 2.06241, saving model to model-BiLSTM-MLP-hybrid-sm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-BiLSTM-MLP-hybrid-sm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.0737 - val_loss: 2.0852\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 2.06241\n",
            "Epoch 39/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 2.0000 - val_loss: 2.0859\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 2.06241\n",
            "Epoch 40/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0452 - val_loss: 2.0778\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 2.06241\n",
            "Epoch 41/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 2.0216 - val_loss: 2.1235\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 2.06241\n",
            "Epoch 42/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 2.0222 - val_loss: 2.0790\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 2.06241\n",
            "Epoch 43/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0344 - val_loss: 2.1164\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 2.06241\n",
            "Epoch 44/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 1.9929 - val_loss: 2.1567\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 2.06241\n",
            "Epoch 45/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0016 - val_loss: 2.1466\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 2.06241\n",
            "Epoch 46/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 2.0049 - val_loss: 2.1185\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 2.06241\n",
            "Epoch 47/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 1.9966 - val_loss: 2.1169\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 2.06241\n",
            "Epoch 48/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.9579 - val_loss: 2.1524\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 2.06241\n",
            "Epoch 49/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.9370 - val_loss: 2.1014\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 2.06241\n",
            "Epoch 50/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.9558 - val_loss: 2.1243\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 2.06241\n",
            "Epoch 51/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.9476 - val_loss: 2.1222\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 2.06241\n",
            "Epoch 52/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.9125 - val_loss: 2.1983\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 2.06241\n",
            "Epoch 53/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 1.9382 - val_loss: 2.1599\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 2.06241\n",
            "Epoch 54/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.8900 - val_loss: 2.1326\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 2.06241\n",
            "Epoch 55/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.9107 - val_loss: 2.1185\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 2.06241\n",
            "Epoch 56/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 1.9392 - val_loss: 2.1031\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 2.06241\n",
            "Epoch 57/60\n",
            "63/63 [==============================] - 9s 140ms/step - loss: 1.9061 - val_loss: 2.1272\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 2.06241\n",
            "Epoch 58/60\n",
            "63/63 [==============================] - 9s 137ms/step - loss: 1.9118 - val_loss: 2.0884\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 2.06241\n",
            "Epoch 59/60\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.8975 - val_loss: 2.1217\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 2.06241\n",
            "Epoch 60/60\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.9096 - val_loss: 2.1176\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 2.06241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXIoqwRppXO_",
        "outputId": "b08971db-0161-4b59-cc0c-cad888363d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train,\r\n",
        "            y_train,\r\n",
        "            epochs=60,\r\n",
        "            batch_size=1000,\r\n",
        "            validation_split = .2,\r\n",
        "            verbose=1,\r\n",
        "            callbacks=callbacks)\r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='Training Loss')\r\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "7/7 [==============================] - 3s 425ms/step - loss: 2.3480 - val_loss: 2.1326\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 2.10211\n",
            "Epoch 2/60\n",
            "7/7 [==============================] - 3s 420ms/step - loss: 2.2955 - val_loss: 2.1076\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2.10211\n",
            "Epoch 3/60\n",
            "7/7 [==============================] - 3s 420ms/step - loss: 2.2940 - val_loss: 2.1848\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 2.10211\n",
            "Epoch 4/60\n",
            "7/7 [==============================] - 3s 418ms/step - loss: 2.3402 - val_loss: 2.1852\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.10211\n",
            "Epoch 5/60\n",
            "7/7 [==============================] - 3s 421ms/step - loss: 2.3181 - val_loss: 2.1113\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 2.10211\n",
            "Epoch 6/60\n",
            "7/7 [==============================] - 3s 420ms/step - loss: 2.2861 - val_loss: 2.1223\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 2.10211\n",
            "Epoch 7/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.3005 - val_loss: 2.1262\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.10211\n",
            "Epoch 8/60\n",
            "7/7 [==============================] - 3s 421ms/step - loss: 2.2894 - val_loss: 2.1477\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 2.10211\n",
            "Epoch 9/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.3010 - val_loss: 2.1410\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 2.10211\n",
            "Epoch 10/60\n",
            "7/7 [==============================] - 3s 417ms/step - loss: 2.2990 - val_loss: 2.1256\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 2.10211\n",
            "Epoch 11/60\n",
            "7/7 [==============================] - 3s 420ms/step - loss: 2.3109 - val_loss: 2.1800\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.10211\n",
            "Epoch 12/60\n",
            "7/7 [==============================] - 3s 420ms/step - loss: 2.2929 - val_loss: 2.2135\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.10211\n",
            "Epoch 13/60\n",
            "7/7 [==============================] - 3s 418ms/step - loss: 2.3303 - val_loss: 2.1159\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.10211\n",
            "Epoch 14/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.2631 - val_loss: 2.1072\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.10211\n",
            "Epoch 15/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.2770 - val_loss: 2.1145\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.10211\n",
            "Epoch 16/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.2939 - val_loss: 2.1347\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.10211\n",
            "Epoch 17/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.2708 - val_loss: 2.1022\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.10211\n",
            "Epoch 18/60\n",
            "7/7 [==============================] - 3s 419ms/step - loss: 2.2765 - val_loss: 2.1198\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.10211\n",
            "Epoch 19/60\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 2.2841"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-357b4134682a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             callbacks=callbacks)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9d6GRYl27Y5"
      },
      "source": [
        "# Model Evaluation\n",
        "This model takes forever to train.  While having a frozen embedding layer helps reduce the number of weights to update, you'll want to train this on something with a good CUDA GPU.  It scores a 1.7 grade level average error, quite a bit better than the FSM accuracy of 2.5.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFoR5aK7u-fn",
        "outputId": "fe1690c2-c26b-4495-e311-401479a33a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>9.0</td>\n",
              "      <td>She had finally gotten her green belt in Tae Kwando. It was an amazing accomplishment for Kameelah D.  a thin African American girl standing about five feet tall. Only four years before  she was told by a doctor that she would never walk again. It was quite evident that not only would she walk again  but she would also run  jump  kick  and punch. When Kameelah was 11  a routine physical uncovered an abnormal curvature in her spine. It was soon after diagnosed as scoliosis. Kameelah  as well as her family  was devastated. They were told by the doctor that only 10 percent of all children are afflicted by scoliosis  but her family just couldnt believe Kameelah was a part of that 10 percent. Her first surgery was scheduled immediately. The doctor had the difficult task of reconstructing Kameelahs entire spine and then re-situating her organs around it. I had never been in the hospital for anything serious before  and Id never had surgery  either. I was so scared  Kameelah recalls. She was given something to fall asleep for the surgery  so that she would not feel anything. Because this surgery dealt with the vertebrae and nerve connections to the brain  the doctor had to make sure that Kameelah could still move her body parts right. Therefore  she was awakened in the middle of the surgery. They would ask me to move my fingers  then my toes. I could barely comprehend what was going on. It was bright  and things werent very clear. In retrospect  I cant believe that I was awake while my back was split open  and the doctors had their hands in there. The first surgery was successful  but Kameelah would have to return two more times for the doctor to completely fix the problem. It was at the end of the third surgery when things went wrong . . . really wrong. The doctor inserted a metal rod  which happened to be too small  into Kameelahs back. As a result  it compressed some of the nerves in her spine. She was practically paralyzed from the waist down. Im really very sorry but . . . I dont think Kameelah will ever be able to walk again  the doctor informed her parents. But Kameelahs father  James  as well as Kameelah herself  refused to accept that prediction. Her father  a registered nurse  insisted that the doctor put her in physical therapy and try to rehabilitate her. He insisted that he be there  too  along with the therapist  helping to rehabilitate his daughter. But the doctor wouldnt oblige. He said that it was a lost cause  and that he knew that Kameelah could never walk again. I was really scared. I just remember telling Dad  Ã¢â‚¬ËœI have to walk. I have to walk  Dad. And he promised me  he swore to me  that I would walk again. He said just what I needed to hear. James kept his promise. He brought Kameelah home in a wheelchair and worked with her  doing exercises that would have been ridiculously easy for any other person  but that were excruciatingly difficult for Kameelah. After about a year  Kameelah was miraculously able to walk with a walker. In no time  she even got strong enough to get along without the walker. Eventually  she walked confidently  and even ran steadily. Now  at the age of twenty-two  she can execute a flying sidekick with the greatest of ease. Not bad for someone who was told she would never walk again  huh? she jokes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Children  as they become adults  become more appreciative of their parents. In The Joy Luck Club  the attitudes of four daughters toward their mothers change as the girls mature and come to realize that their mothers arent so different after all. As children  the daughters in this book are ashamed of their mothers and dont take them very seriously  dismissing them as quirky and odd. I could never tell my father . . . How could I tell him my mother was crazy? (p. 117). They dont try to comprehend their culture  which is a big part of understanding their traditional Chinese mothers. On page 6  one of the daughters states  I can never remember things I dont understand in the first place  referring to Chinese expressions her mother used. When their mothers show pride in them  the girls only show their embarrassment. One daughter shows her shame when she says to her mother  I wish you wouldnt do that  telling everyone Im your daughter (p. 101). The girls cannot relate to their mothers because they were raised in a different world. No matter how much the mothers care for them or how much they sacrifice to make their girls lives better  the daughters are blind to their mothers pain and feelings. All four of the Joy Luck mothers need their daughters to understand them  pass on their spirit after they are gone  and understand what they have gone through for their girls. One mother dreams of doing this on her trip to a new life: In America I will have a daughter just like me . . . over there nobody will look down on her . . . and she will always be too full to swallow any sorrow! She will know my meaning because I will give her this swan . . . it carries with it all my good intentions (pp. 3-4). Another mother plans how she will give her daughter this perception: She [my daughter] has no chi . . . How can I leave the world without leaving her my spirit? So this is what I will do. I will gather together my past and . . . see a thing that has already happened. The pain that cut my spirit loose. I will hold that pain in my hand until it becomes hard and shiny  more clear. And then my fierceness can come back . . . I will use this sharp pain to penetrate my daughters tough skin and cut her tiger spirit loose. She will fight me  because this is the nature of two tigers. But I will win and give her my spirit because this is why a mother loves a daughter. (p. 286) Things dont exactly turn out the way the mothers hope  though. Their hopes and dreams are shattered when they realize their daughters misconceptions of them. On page 282  a mother laments  When my daughter looks at me  she sees a small  old lady. If she had chuming [inside knowledge of things] she would see a tiger lady. One daughter sees the fear of the remaining mothers after she tells them that she doesnt know anything about her dead mother that she can pass on: They are frightened. In me  they see their own daughters  just as ignorant  just as unmindful of all the truths and hopes they have brought to America. They see daughters who grow impatient when their mothers talk in Chinese  who think they are stupid when they explain things in fractured English . . . They see daughters who will bear grandchildren born without any connecting hope passed from generation to generation. (p. 31)  This fear does not persist  however. As the daughters mature  the two generations discover that they arent so different after all. One mother says  She puts her face next to mine  side by side  and we look at each other in the mirror . . . these two faces  I think  so much the same! The same happiness  the same sadness  the same good fortune  the same faults (p. 292). One daughter  after her mothers death  sits down to play the piano that she had refused to touch before to defy her mother. Amy Tan uses the metaphor of two piano pieces to compare the mother to this daughter: The piece I had played for the recital . . . was on the left-hand side of the page . . . and for the first time . . . I noticed the piece on the right-hand side . . . It had a lighter melody but the same flowing rhythm [as the recital piece and] . . . was longer but faster. And after I played them both . . . I realized they were two halves of the same song (p. 155). The daughters  as they grow to be adults  become more appreciative of their mothers. Their attitudes change over time to create an understanding and respect that hadnt been there before: I saw what I had been fighting for. It was for me  a scared child  who had run away a long time ago to what I had imagined was a safer place. And hiding in this place  behind my invisible barriers  I knew what lay on the other side: her side attacks. Her secret weapons. Her uncanny ability to find my weakest spots. But in the brief instant that I had peered over the barriers I could finally see what was really there: an old woman  a wok for her armor  a knitting needle for her sword  getting a little crabby as she waited patiently for her daughter to invite her in. (pp. 203-204) In conclusion  as children  the daughters didnt understand their mothers or their culture. The daughters were being raised in a different world. Their perceptions of their mothers changed  though  as they grew up and realized that they werent so different from them after all. They finally understood and respected their traditional Chinese mothers.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Do you have a favorite place to goÃ¢â‚¬â€a place with family  good weather  and fun things to do like crabbing? Im glad I do. New Jersey is my favorite place for many reasons. The first reason is my family. Over half of my family lives in New Jersey. When I visit  my cousins and I laugh and play all day and night. My uncles and aunts take me to the boardwalk where we ride roller coasters. We devour juicy caramel-covered apples and foot-long hot dogs. My family is fun to be with. The second reason for New Jersey being my favorite place is the weather. Instead of being hot and sweaty  its always cool and moist. When I think about my visits  I can just feel the crisp fall breeze in my hair. I can just see the white  fluffy winter snow. I can just hear the soft spring trickles of rain splashing on the sidewalks. I can just feel the warm summer sun on my face. The weather is great! The third reason for New Jersey being my favorite place is crabbing. If its crab season  we crab. We keep the blue crabs and the snow crabs  and we let the others go. Sometimes we catch crabs on hooks  and sometimes we lower crab cages into the bay. Then we pull them out later. One time my brother caught a crab so big that it got stuck in the crab cage! The crab finally got out  but it hurt one of its legs and broke the cage trying. Poor crab! For all these reasons  New Jersey is my favorite place to go. If you dont have a favorite place  I think you should search for one. Its good to visit a favorite placeÃ¢â‚¬â€a place where you can make special memories. By the way  if you crab at your special place  be sure to get a big crab cage.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Eyuuuuuuuuu! Nasty! This book was very gross at the beginning because the bullies made a bet with Tom. The bet was for Tom to eat fifteen worms for 50 dollars. What brought me in to the story was the lead which was Hey Tom where were you last night? As I got further into the story it kind of made me want to try a worm Ã¢â‚¬Ëœcause in the fifth and sixth chapter it says  The worms were okay. During the eighth and ninth chapter Tom got a very bad stomach ache from all those worms. Tom didnt only lose 50 dollars he lost energy from those worms because when he got the stomach ache he couldnt do anything. How he lost is he missed his worm. When Toms mom learned about the bet she punished him by sending him to his room till dinner. The author included lots of detail. It made really wonderful pictures in my mind from the long and descriptive words that the author used. I think the author wrote this book to tell us not to bet. It is a bad thing to bet because it can hurt your body. I recommend this book for readers who like adventures and interesting stories.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Fine arts are important in the curriculum because of what they do for learning  stated Patty Taylor  arts consultant for the California State Department of Education. In other words  the arts  especially music  should be part of every schools curriculum at every grade level. Music makes students smarter  gives children something positive to do  and builds self-confidence. Most students dont have a chance to learn music outside of school  and everyone deserves that opportunity. Students would be much smarter if they had some music experience. They would improve their classroom skills  like paying attention  following directions  and participating without interrupting. People develop all these skills when they learn music. Musicians are also better in math  and they get higher S.A.T. scores. For instance  a study by the College Entrance Examination Board reported  Students with 20 units of arts and music scored 128 points higher on the S.A.T. verbal and 118 points higher in math. A Rockefeller Foundation study states that music majors have the highest rate of admittance to medical school. Making music also lets children use their imaginations  unlike playing with video games and electronic stuffed animals. It provides students a chance to try out their own ideas  according to the California Educator. Music makes children well-rounded students. Music not only makes children better students but also gives them something positive to do. In a music program  children can be part of a band or choir instead of getting into trouble. Parents can enjoy listening to their childrens music instead of seeing them glued to a computer or TV screen. In band  students get to be part of a team. They can interact with old friends and make new friends through music. In fact  on her Web site The Musicians Brain  Lois Svard explains how music stimulates mirror neurons  which synchronize performers but also help them empathize with each other. As the great choral conductor Eric Whitacre said  directing a choir is all about getting a room of people to breathe together. In many ways  music helps people connect. Music builds self-confidence. It gives children a sense of accomplishment and success. Making music is something for them to be proud of  and it lets kids practice performing in front of an audience. As reported in the California Educator  It gives [students] self-confidence and a feeling of importance to have a skill someone appreciates. They are also learning how to accomplish something from beginning to end and actually come out with a product that they can be proud of. Music gives children an outlet for self-expression  and that helps develop their self-confidence. Once again  music is important because it can make children better students  give them something positive to do  and build their character. Unfortunately  the children who need music lessons the most usually dont have access to them outside of school. That is why music should be offered in every single grade in every school.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Chores are boring! Scrubbing toilets  cleaning sinks  and washing bathtubs take up a lot of my time and are not fun at all. Toilets! When youre scrubbing toilets make sure they are not stinky. Ive scrubbed one before and I was lucky it didnt stink. I think toilets are one of the hardest things to scrub in the bathroom because it is hard to get up around the rim. Sinks are one of the easiest things to clean in the bathroom because they have no rims and they are small. I have cleaned one before and it was pretty easy. Bathtubs  ever washed one? They are big  they are deep  and it is hard to get up around the sides. The bathtub is the hardest  I think  to wash in the bathroom. All chores are boring  especially making my bed. Cleaning my room is OK because I have to organize  and I like organizing. Dusting is the worst: dust  set down  pick up  dust  set down. There are so many things to dust  and its no fun. Chores arent the worst but theyre definitely not the best!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Jean Baptiste de Lamarck and Charles Darwin were both naturalists that had theories about organisms getting helpful variations. Lamarcks theory was called the theory of acquired characteristics and Darwins was called the theory of evolution by natural selection. Lamarck and Darwins theories are the same and different in some ways.    Darwin and Lamarcks theories were very different. Darwin theory said that organisms get helpful variation before changes in the environment. He thought they got the variation by chance at birth. He explained that the reason giraffes had long necks was because some giraffes had a variation which was a longer neck. The giraffes with short necks could only get food on the ground so they had to compete for it so they died. The giraffes with the long necks did not have to compete because they could get the food up high and they survived and passed the long necks onto their young.  Lamarck theory said that organisms got helpful variation after  a change in the environment. He said that giraffes got long necks when the food on the ground ran out. The giraffes needed to eat food and there was food up high so they stretched out their necks. They then passed it on to their young. Their theories are different because Lamarck thought that organisms changed out of need and after a change in the environment and Darwin thought organisms changed by chance when they were born and before there was a change in the environment.    Darwin and Lamarcks theories were very different but they were also very similar. They both thought that organisms changed. They thought these changes could be very useful and could help them survive. The changes could then get passed down to the young. That is how Lamarck and Darwins theories are similar.    Lamarck and Darwins theories are both the same and different in some ways.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Oh my God  I exclaimed  Whats John doing out there? Why is he on his hands and knees  Mom? I looked out the big kitchen window  wondering if my eight year old brother was all right. He was on hands and knees in our back yard looking rather distressed. Then he threw up. I ran out to see what happened. John stood up and smiled. I was panicked. You have to come inside now! What happened?! I asked  almost screaming. I ate too much at breakfast. I want to keep playing. Im not sick  Ellie! He pouted at me for the next five minutes until agreeing to come inside with me or  as I threatened  mom would be mad. The minute we got inside he started acting like an angel. Little brat. I thought. I hate him. This typical incident was just yesterday  but I can still remember the morning of March 2nd 1969  a day that has affected my life more than I ever could have suspected. To me  a five year old girl  it seemed pretty simple: Mom was having a baby. I couldnt comprehend the implications this would have on my life. When I woke up that morning I went downstairs to demand breakfast  but  instead  grandma was there  and said bluntly  Your moms at the hospital having the baby. Oh  I thought  completely unaffected. I called my friend  Jakie  who lived across the yard  to come over and play. Jakie was my best friend  and she flipped out wondering about the baby and what was going on. Then I started to get curious about it too. My sister  who had already gone through the birth of a younger sibling (me!)  seemed less than enthusiastic. I started to miss my mom  something that had rarely happened before. When Coral  my mom and Dads closest friend  pulled up in our driveway  everyone told me that we were going to the hospital to see my mom and my new brother. I felt my first pangs of jealousy. We all ran to see my mom  who had been in labor all night. I jumped right into the bed next to my exhausted mother as soon as we got into her room. My brother was being weighed and measured  but we got to hold him soon. I was secretly scared because he was so small and delicate. He looked sort of gross  but everyone else seemed to love him  so I didnt say anything. You could barely see his face because of all the wrinkles. Gross! I thought in disgust! His whole body was covered in wrinkles  and he was on the redish side. We decided to call him John Jordan Strosahl. John (now Johnny-Jordan) grew up to be a superbly cute baby Ã¢â‚¬â€ to my disappointment. He had golden blonde baby curls spilling off his head which reminded me of the foam on a coke. Big  round  sapphire eyes lit up his face Ã¢â‚¬â€ as if he need it with such a great big  gummy smile. Thats what has bugged me most for all these years. Frankly  John was the cutest baby  and I knew that the amount of doting time we got wasnt equal; this made me pretty mad.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>9.0</td>\n",
              "      <td>As I step out of the pick-up it hits me  the smell of manure drifting down from the barn. A sliding glass door swishes open  and clomping down the ramp is my boss  Robert Taylor. Put your lunch in the van  Steve. Ill be there in a minute. I turn and walk toward the van  an old 69 green and white Dodge Sportsman  covered with an inch of dust. When I open the door and peer in  it reminds me of a walk-in trash can. The floor lies out of sight underneath a sea of garbage. I kick some garbage out of my way and hop up in the seat. Before long  here comes Rob  clomping across the driveway. He opens the door  groans as he gets up into his seat  cranks the motor over  and the motor sputters to a start  filling the air inside the van with the smell of burnt oil. My first impression is that we wont make it out of the driveway  but we sputter out onto the road  and head toward town. When we pull into the circular drive  I peer through the dust-smudged window to find that the tractor is still there. On the side it reads Massey-Ferguson  but with Robert  its hard telling what it really is. As I sit down in the seat I adjust the hunk of foam rubber to a comfortable position. Once I have accomplished this  I sit down and start cranking on the prehistoric starter. Slowly  and then more rapidly  like a steam engine building up speed  the black smoke rolls out of the pipe functioning as a muffler and away we go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Right now I want you to pretend you are in a store. As you walk around  you see that some products are much less expensive than others. Now  look at the labels on these cheaper items. You will probably notice that many of these labels say  Made in China  or Made in Honduras. Have you ever stopped to wonder why products made in these countries are so much more affordable than things manufactured right here on American soil? Well  before you buy another inexpensive article of clothing  pair of shoes  sporting good  carpet  or any other product  you might want to think this through. Child labor has long been banned in America  but out of sight should not mean out of mind. Over 200 million children world-wide work full time in conditions not fit for an animal. That means that they do not play sports  they do not attend school  and they do not have fun. These children are prisoners. Take  for example  Pakistan and India. In these countries  a bonded labor system forces child laborers  some as young as four years old  to work for a single employer for many years. They are sometimes literally tied to their loom to ensure they are not slacking off. In return for their servitude  they receive a place to sleep and just enough food to sustain them. In Honduras  13% of the workforce is between 12 and 15 years old. There are no laws restricting the ages of the employees  nor are there any limits on the hours they can work. It is not uncommon for a 13 year old child to put in a 14 hour day with no break. However  Honduran employers are required to have a night school for their young laborers to attend. Children put to work weaving carpets  making soap  or any other number of jobs are never paid in full for their toil. Here in the U.S.  the minimum wage is over five dollars an hour. In countries that hire minors to do the dirty work there is almost never a minimum pay requirement. In Haiti  children are  on average  paid 28 cents per hour. In Sri Lanka  the median is 18 cents. Vietnamese and Chinese children should not expect their wages to exceed 11 cents. These numbers are truly tragic. Before you buy something made in a country that condones the labor of young children who work for pennies just so that you can have a more inexpensive item  please think about the situation you are contributing to.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Grade                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Text\n",
              "73     9.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     She had finally gotten her green belt in Tae Kwando. It was an amazing accomplishment for Kameelah D.  a thin African American girl standing about five feet tall. Only four years before  she was told by a doctor that she would never walk again. It was quite evident that not only would she walk again  but she would also run  jump  kick  and punch. When Kameelah was 11  a routine physical uncovered an abnormal curvature in her spine. It was soon after diagnosed as scoliosis. Kameelah  as well as her family  was devastated. They were told by the doctor that only 10 percent of all children are afflicted by scoliosis  but her family just couldnt believe Kameelah was a part of that 10 percent. Her first surgery was scheduled immediately. The doctor had the difficult task of reconstructing Kameelahs entire spine and then re-situating her organs around it. I had never been in the hospital for anything serious before  and Id never had surgery  either. I was so scared  Kameelah recalls. She was given something to fall asleep for the surgery  so that she would not feel anything. Because this surgery dealt with the vertebrae and nerve connections to the brain  the doctor had to make sure that Kameelah could still move her body parts right. Therefore  she was awakened in the middle of the surgery. They would ask me to move my fingers  then my toes. I could barely comprehend what was going on. It was bright  and things werent very clear. In retrospect  I cant believe that I was awake while my back was split open  and the doctors had their hands in there. The first surgery was successful  but Kameelah would have to return two more times for the doctor to completely fix the problem. It was at the end of the third surgery when things went wrong . . . really wrong. The doctor inserted a metal rod  which happened to be too small  into Kameelahs back. As a result  it compressed some of the nerves in her spine. She was practically paralyzed from the waist down. Im really very sorry but . . . I dont think Kameelah will ever be able to walk again  the doctor informed her parents. But Kameelahs father  James  as well as Kameelah herself  refused to accept that prediction. Her father  a registered nurse  insisted that the doctor put her in physical therapy and try to rehabilitate her. He insisted that he be there  too  along with the therapist  helping to rehabilitate his daughter. But the doctor wouldnt oblige. He said that it was a lost cause  and that he knew that Kameelah could never walk again. I was really scared. I just remember telling Dad  Ã¢â‚¬ËœI have to walk. I have to walk  Dad. And he promised me  he swore to me  that I would walk again. He said just what I needed to hear. James kept his promise. He brought Kameelah home in a wheelchair and worked with her  doing exercises that would have been ridiculously easy for any other person  but that were excruciatingly difficult for Kameelah. After about a year  Kameelah was miraculously able to walk with a walker. In no time  she even got strong enough to get along without the walker. Eventually  she walked confidently  and even ran steadily. Now  at the age of twenty-two  she can execute a flying sidekick with the greatest of ease. Not bad for someone who was told she would never walk again  huh? she jokes.\n",
              "167    9.0  Children  as they become adults  become more appreciative of their parents. In The Joy Luck Club  the attitudes of four daughters toward their mothers change as the girls mature and come to realize that their mothers arent so different after all. As children  the daughters in this book are ashamed of their mothers and dont take them very seriously  dismissing them as quirky and odd. I could never tell my father . . . How could I tell him my mother was crazy? (p. 117). They dont try to comprehend their culture  which is a big part of understanding their traditional Chinese mothers. On page 6  one of the daughters states  I can never remember things I dont understand in the first place  referring to Chinese expressions her mother used. When their mothers show pride in them  the girls only show their embarrassment. One daughter shows her shame when she says to her mother  I wish you wouldnt do that  telling everyone Im your daughter (p. 101). The girls cannot relate to their mothers because they were raised in a different world. No matter how much the mothers care for them or how much they sacrifice to make their girls lives better  the daughters are blind to their mothers pain and feelings. All four of the Joy Luck mothers need their daughters to understand them  pass on their spirit after they are gone  and understand what they have gone through for their girls. One mother dreams of doing this on her trip to a new life: In America I will have a daughter just like me . . . over there nobody will look down on her . . . and she will always be too full to swallow any sorrow! She will know my meaning because I will give her this swan . . . it carries with it all my good intentions (pp. 3-4). Another mother plans how she will give her daughter this perception: She [my daughter] has no chi . . . How can I leave the world without leaving her my spirit? So this is what I will do. I will gather together my past and . . . see a thing that has already happened. The pain that cut my spirit loose. I will hold that pain in my hand until it becomes hard and shiny  more clear. And then my fierceness can come back . . . I will use this sharp pain to penetrate my daughters tough skin and cut her tiger spirit loose. She will fight me  because this is the nature of two tigers. But I will win and give her my spirit because this is why a mother loves a daughter. (p. 286) Things dont exactly turn out the way the mothers hope  though. Their hopes and dreams are shattered when they realize their daughters misconceptions of them. On page 282  a mother laments  When my daughter looks at me  she sees a small  old lady. If she had chuming [inside knowledge of things] she would see a tiger lady. One daughter sees the fear of the remaining mothers after she tells them that she doesnt know anything about her dead mother that she can pass on: They are frightened. In me  they see their own daughters  just as ignorant  just as unmindful of all the truths and hopes they have brought to America. They see daughters who grow impatient when their mothers talk in Chinese  who think they are stupid when they explain things in fractured English . . . They see daughters who will bear grandchildren born without any connecting hope passed from generation to generation. (p. 31)  This fear does not persist  however. As the daughters mature  the two generations discover that they arent so different after all. One mother says  She puts her face next to mine  side by side  and we look at each other in the mirror . . . these two faces  I think  so much the same! The same happiness  the same sadness  the same good fortune  the same faults (p. 292). One daughter  after her mothers death  sits down to play the piano that she had refused to touch before to defy her mother. Amy Tan uses the metaphor of two piano pieces to compare the mother to this daughter: The piece I had played for the recital . . . was on the left-hand side of the page . . . and for the first time . . . I noticed the piece on the right-hand side . . . It had a lighter melody but the same flowing rhythm [as the recital piece and] . . . was longer but faster. And after I played them both . . . I realized they were two halves of the same song (p. 155). The daughters  as they grow to be adults  become more appreciative of their mothers. Their attitudes change over time to create an understanding and respect that hadnt been there before: I saw what I had been fighting for. It was for me  a scared child  who had run away a long time ago to what I had imagined was a safer place. And hiding in this place  behind my invisible barriers  I knew what lay on the other side: her side attacks. Her secret weapons. Her uncanny ability to find my weakest spots. But in the brief instant that I had peered over the barriers I could finally see what was really there: an old woman  a wok for her armor  a knitting needle for her sword  getting a little crabby as she waited patiently for her daughter to invite her in. (pp. 203-204) In conclusion  as children  the daughters didnt understand their mothers or their culture. The daughters were being raised in a different world. Their perceptions of their mothers changed  though  as they grew up and realized that they werent so different from them after all. They finally understood and respected their traditional Chinese mothers.\n",
              "26     4.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Do you have a favorite place to goÃ¢â‚¬â€a place with family  good weather  and fun things to do like crabbing? Im glad I do. New Jersey is my favorite place for many reasons. The first reason is my family. Over half of my family lives in New Jersey. When I visit  my cousins and I laugh and play all day and night. My uncles and aunts take me to the boardwalk where we ride roller coasters. We devour juicy caramel-covered apples and foot-long hot dogs. My family is fun to be with. The second reason for New Jersey being my favorite place is the weather. Instead of being hot and sweaty  its always cool and moist. When I think about my visits  I can just feel the crisp fall breeze in my hair. I can just see the white  fluffy winter snow. I can just hear the soft spring trickles of rain splashing on the sidewalks. I can just feel the warm summer sun on my face. The weather is great! The third reason for New Jersey being my favorite place is crabbing. If its crab season  we crab. We keep the blue crabs and the snow crabs  and we let the others go. Sometimes we catch crabs on hooks  and sometimes we lower crab cages into the bay. Then we pull them out later. One time my brother caught a crab so big that it got stuck in the crab cage! The crab finally got out  but it hurt one of its legs and broke the cage trying. Poor crab! For all these reasons  New Jersey is my favorite place to go. If you dont have a favorite place  I think you should search for one. Its good to visit a favorite placeÃ¢â‚¬â€a place where you can make special memories. By the way  if you crab at your special place  be sure to get a big crab cage.\n",
              "105    3.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Eyuuuuuuuuu! Nasty! This book was very gross at the beginning because the bullies made a bet with Tom. The bet was for Tom to eat fifteen worms for 50 dollars. What brought me in to the story was the lead which was Hey Tom where were you last night? As I got further into the story it kind of made me want to try a worm Ã¢â‚¬Ëœcause in the fifth and sixth chapter it says  The worms were okay. During the eighth and ninth chapter Tom got a very bad stomach ache from all those worms. Tom didnt only lose 50 dollars he lost energy from those worms because when he got the stomach ache he couldnt do anything. How he lost is he missed his worm. When Toms mom learned about the bet she punished him by sending him to his room till dinner. The author included lots of detail. It made really wonderful pictures in my mind from the long and descriptive words that the author used. I think the author wrote this book to tell us not to bet. It is a bad thing to bet because it can hurt your body. I recommend this book for readers who like adventures and interesting stories. \n",
              "53     6.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Fine arts are important in the curriculum because of what they do for learning  stated Patty Taylor  arts consultant for the California State Department of Education. In other words  the arts  especially music  should be part of every schools curriculum at every grade level. Music makes students smarter  gives children something positive to do  and builds self-confidence. Most students dont have a chance to learn music outside of school  and everyone deserves that opportunity. Students would be much smarter if they had some music experience. They would improve their classroom skills  like paying attention  following directions  and participating without interrupting. People develop all these skills when they learn music. Musicians are also better in math  and they get higher S.A.T. scores. For instance  a study by the College Entrance Examination Board reported  Students with 20 units of arts and music scored 128 points higher on the S.A.T. verbal and 118 points higher in math. A Rockefeller Foundation study states that music majors have the highest rate of admittance to medical school. Making music also lets children use their imaginations  unlike playing with video games and electronic stuffed animals. It provides students a chance to try out their own ideas  according to the California Educator. Music makes children well-rounded students. Music not only makes children better students but also gives them something positive to do. In a music program  children can be part of a band or choir instead of getting into trouble. Parents can enjoy listening to their childrens music instead of seeing them glued to a computer or TV screen. In band  students get to be part of a team. They can interact with old friends and make new friends through music. In fact  on her Web site The Musicians Brain  Lois Svard explains how music stimulates mirror neurons  which synchronize performers but also help them empathize with each other. As the great choral conductor Eric Whitacre said  directing a choir is all about getting a room of people to breathe together. In many ways  music helps people connect. Music builds self-confidence. It gives children a sense of accomplishment and success. Making music is something for them to be proud of  and it lets kids practice performing in front of an audience. As reported in the California Educator  It gives [students] self-confidence and a feeling of importance to have a skill someone appreciates. They are also learning how to accomplish something from beginning to end and actually come out with a product that they can be proud of. Music gives children an outlet for self-expression  and that helps develop their self-confidence. Once again  music is important because it can make children better students  give them something positive to do  and build their character. Unfortunately  the children who need music lessons the most usually dont have access to them outside of school. That is why music should be offered in every single grade in every school.\n",
              "..     ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...\n",
              "103    3.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Chores are boring! Scrubbing toilets  cleaning sinks  and washing bathtubs take up a lot of my time and are not fun at all. Toilets! When youre scrubbing toilets make sure they are not stinky. Ive scrubbed one before and I was lucky it didnt stink. I think toilets are one of the hardest things to scrub in the bathroom because it is hard to get up around the rim. Sinks are one of the easiest things to clean in the bathroom because they have no rims and they are small. I have cleaned one before and it was pretty easy. Bathtubs  ever washed one? They are big  they are deep  and it is hard to get up around the sides. The bathtub is the hardest  I think  to wash in the bathroom. All chores are boring  especially making my bed. Cleaning my room is OK because I have to organize  and I like organizing. Dusting is the worst: dust  set down  pick up  dust  set down. There are so many things to dust  and its no fun. Chores arent the worst but theyre definitely not the best! \n",
              "225    7.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Jean Baptiste de Lamarck and Charles Darwin were both naturalists that had theories about organisms getting helpful variations. Lamarcks theory was called the theory of acquired characteristics and Darwins was called the theory of evolution by natural selection. Lamarck and Darwins theories are the same and different in some ways.    Darwin and Lamarcks theories were very different. Darwin theory said that organisms get helpful variation before changes in the environment. He thought they got the variation by chance at birth. He explained that the reason giraffes had long necks was because some giraffes had a variation which was a longer neck. The giraffes with short necks could only get food on the ground so they had to compete for it so they died. The giraffes with the long necks did not have to compete because they could get the food up high and they survived and passed the long necks onto their young.  Lamarck theory said that organisms got helpful variation after  a change in the environment. He said that giraffes got long necks when the food on the ground ran out. The giraffes needed to eat food and there was food up high so they stretched out their necks. They then passed it on to their young. Their theories are different because Lamarck thought that organisms changed out of need and after a change in the environment and Darwin thought organisms changed by chance when they were born and before there was a change in the environment.    Darwin and Lamarcks theories were very different but they were also very similar. They both thought that organisms changed. They thought these changes could be very useful and could help them survive. The changes could then get passed down to the young. That is how Lamarck and Darwins theories are similar.    Lamarck and Darwins theories are both the same and different in some ways.  \n",
              "127    6.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Oh my God  I exclaimed  Whats John doing out there? Why is he on his hands and knees  Mom? I looked out the big kitchen window  wondering if my eight year old brother was all right. He was on hands and knees in our back yard looking rather distressed. Then he threw up. I ran out to see what happened. John stood up and smiled. I was panicked. You have to come inside now! What happened?! I asked  almost screaming. I ate too much at breakfast. I want to keep playing. Im not sick  Ellie! He pouted at me for the next five minutes until agreeing to come inside with me or  as I threatened  mom would be mad. The minute we got inside he started acting like an angel. Little brat. I thought. I hate him. This typical incident was just yesterday  but I can still remember the morning of March 2nd 1969  a day that has affected my life more than I ever could have suspected. To me  a five year old girl  it seemed pretty simple: Mom was having a baby. I couldnt comprehend the implications this would have on my life. When I woke up that morning I went downstairs to demand breakfast  but  instead  grandma was there  and said bluntly  Your moms at the hospital having the baby. Oh  I thought  completely unaffected. I called my friend  Jakie  who lived across the yard  to come over and play. Jakie was my best friend  and she flipped out wondering about the baby and what was going on. Then I started to get curious about it too. My sister  who had already gone through the birth of a younger sibling (me!)  seemed less than enthusiastic. I started to miss my mom  something that had rarely happened before. When Coral  my mom and Dads closest friend  pulled up in our driveway  everyone told me that we were going to the hospital to see my mom and my new brother. I felt my first pangs of jealousy. We all ran to see my mom  who had been in labor all night. I jumped right into the bed next to my exhausted mother as soon as we got into her room. My brother was being weighed and measured  but we got to hold him soon. I was secretly scared because he was so small and delicate. He looked sort of gross  but everyone else seemed to love him  so I didnt say anything. You could barely see his face because of all the wrinkles. Gross! I thought in disgust! His whole body was covered in wrinkles  and he was on the redish side. We decided to call him John Jordan Strosahl. John (now Johnny-Jordan) grew up to be a superbly cute baby Ã¢â‚¬â€ to my disappointment. He had golden blonde baby curls spilling off his head which reminded me of the foam on a coke. Big  round  sapphire eyes lit up his face Ã¢â‚¬â€ as if he need it with such a great big  gummy smile. Thats what has bugged me most for all these years. Frankly  John was the cutest baby  and I knew that the amount of doting time we got wasnt equal; this made me pretty mad.\n",
              "143    9.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             As I step out of the pick-up it hits me  the smell of manure drifting down from the barn. A sliding glass door swishes open  and clomping down the ramp is my boss  Robert Taylor. Put your lunch in the van  Steve. Ill be there in a minute. I turn and walk toward the van  an old 69 green and white Dodge Sportsman  covered with an inch of dust. When I open the door and peer in  it reminds me of a walk-in trash can. The floor lies out of sight underneath a sea of garbage. I kick some garbage out of my way and hop up in the seat. Before long  here comes Rob  clomping across the driveway. He opens the door  groans as he gets up into his seat  cranks the motor over  and the motor sputters to a start  filling the air inside the van with the smell of burnt oil. My first impression is that we wont make it out of the driveway  but we sputter out onto the road  and head toward town. When we pull into the circular drive  I peer through the dust-smudged window to find that the tractor is still there. On the side it reads Massey-Ferguson  but with Robert  its hard telling what it really is. As I sit down in the seat I adjust the hunk of foam rubber to a comfortable position. Once I have accomplished this  I sit down and start cranking on the prehistoric starter. Slowly  and then more rapidly  like a steam engine building up speed  the black smoke rolls out of the pipe functioning as a muffler and away we go.\n",
              "135    6.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Right now I want you to pretend you are in a store. As you walk around  you see that some products are much less expensive than others. Now  look at the labels on these cheaper items. You will probably notice that many of these labels say  Made in China  or Made in Honduras. Have you ever stopped to wonder why products made in these countries are so much more affordable than things manufactured right here on American soil? Well  before you buy another inexpensive article of clothing  pair of shoes  sporting good  carpet  or any other product  you might want to think this through. Child labor has long been banned in America  but out of sight should not mean out of mind. Over 200 million children world-wide work full time in conditions not fit for an animal. That means that they do not play sports  they do not attend school  and they do not have fun. These children are prisoners. Take  for example  Pakistan and India. In these countries  a bonded labor system forces child laborers  some as young as four years old  to work for a single employer for many years. They are sometimes literally tied to their loom to ensure they are not slacking off. In return for their servitude  they receive a place to sleep and just enough food to sustain them. In Honduras  13% of the workforce is between 12 and 15 years old. There are no laws restricting the ages of the employees  nor are there any limits on the hours they can work. It is not uncommon for a 13 year old child to put in a 14 hour day with no break. However  Honduran employers are required to have a night school for their young laborers to attend. Children put to work weaving carpets  making soap  or any other number of jobs are never paid in full for their toil. Here in the U.S.  the minimum wage is over five dollars an hour. In countries that hire minors to do the dirty work there is almost never a minimum pay requirement. In Haiti  children are  on average  paid 28 cents per hour. In Sri Lanka  the median is 18 cents. Vietnamese and Chinese children should not expect their wages to exceed 11 cents. These numbers are truly tragic. Before you buy something made in a country that condones the labor of young children who work for pennies just so that you can have a more inexpensive item  please think about the situation you are contributing to.\n",
              "\n",
              "[67 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvhiI9o_u3gu",
        "outputId": "35227c46-9566-48f0-bc19-5d4fbc62d3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "separate_sentences(df)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>If I were president  Id be responsible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Id look alert and run the United States like it should be run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Id be honest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Then the people would trust me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>I would be a good president because I have faith in the people of the United States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9957</th>\n",
              "      <td>12.0</td>\n",
              "      <td>TIG welding is something that needs to be learned not only by textbook or paper\\r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9958</th>\n",
              "      <td>12.0</td>\n",
              "      <td>but also by hands on learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9959</th>\n",
              "      <td>12.0</td>\n",
              "      <td>And thankfully, I have gotten that experience to weld hands on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9960</th>\n",
              "      <td>12.0</td>\n",
              "      <td>It makes\\r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9961</th>\n",
              "      <td>12.0</td>\n",
              "      <td>learning so much easier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9962 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Grade                                                                                  Text\n",
              "0       2.0                                                If I were president  Id be responsible\n",
              "1       2.0                         Id look alert and run the United States like it should be run\n",
              "2       2.0                                                                          Id be honest\n",
              "3       2.0                                                        Then the people would trust me\n",
              "4       2.0   I would be a good president because I have faith in the people of the United States\n",
              "...     ...                                                                                   ...\n",
              "9957   12.0     TIG welding is something that needs to be learned not only by textbook or paper\\r\n",
              "9958   12.0                                                         but also by hands on learning\n",
              "9959   12.0                        And thankfully, I have gotten that experience to weld hands on\n",
              "9960   12.0                                                                            It makes\\r\n",
              "9961   12.0                                                               learning so much easier\n",
              "\n",
              "[9962 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etgq3QcfvSG-",
        "outputId": "df5a09a8-cf95-40e8-e3cd-a51a1133711d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>9.0</td>\n",
              "      <td>She had finally gotten her green belt in Tae Kwando. It was an amazing accomplishment for Kameelah D.  a thin African American girl standing about five feet tall. Only four years before  she was told by a doctor that she would never walk again. It was quite evident that not only would she walk again  but she would also run  jump  kick  and punch. When Kameelah was 11  a routine physical uncovered an abnormal curvature in her spine. It was soon after diagnosed as scoliosis. Kameelah  as well as her family  was devastated. They were told by the doctor that only 10 percent of all children are afflicted by scoliosis  but her family just couldnt believe Kameelah was a part of that 10 percent. Her first surgery was scheduled immediately. The doctor had the difficult task of reconstructing Kameelahs entire spine and then re-situating her organs around it. I had never been in the hospital for anything serious before  and Id never had surgery  either. I was so scared  Kameelah recalls. She was given something to fall asleep for the surgery  so that she would not feel anything. Because this surgery dealt with the vertebrae and nerve connections to the brain  the doctor had to make sure that Kameelah could still move her body parts right. Therefore  she was awakened in the middle of the surgery. They would ask me to move my fingers  then my toes. I could barely comprehend what was going on. It was bright  and things werent very clear. In retrospect  I cant believe that I was awake while my back was split open  and the doctors had their hands in there. The first surgery was successful  but Kameelah would have to return two more times for the doctor to completely fix the problem. It was at the end of the third surgery when things went wrong . . . really wrong. The doctor inserted a metal rod  which happened to be too small  into Kameelahs back. As a result  it compressed some of the nerves in her spine. She was practically paralyzed from the waist down. Im really very sorry but . . . I dont think Kameelah will ever be able to walk again  the doctor informed her parents. But Kameelahs father  James  as well as Kameelah herself  refused to accept that prediction. Her father  a registered nurse  insisted that the doctor put her in physical therapy and try to rehabilitate her. He insisted that he be there  too  along with the therapist  helping to rehabilitate his daughter. But the doctor wouldnt oblige. He said that it was a lost cause  and that he knew that Kameelah could never walk again. I was really scared. I just remember telling Dad  Ã¢â‚¬ËœI have to walk. I have to walk  Dad. And he promised me  he swore to me  that I would walk again. He said just what I needed to hear. James kept his promise. He brought Kameelah home in a wheelchair and worked with her  doing exercises that would have been ridiculously easy for any other person  but that were excruciatingly difficult for Kameelah. After about a year  Kameelah was miraculously able to walk with a walker. In no time  she even got strong enough to get along without the walker. Eventually  she walked confidently  and even ran steadily. Now  at the age of twenty-two  she can execute a flying sidekick with the greatest of ease. Not bad for someone who was told she would never walk again  huh? she jokes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Children  as they become adults  become more appreciative of their parents. In The Joy Luck Club  the attitudes of four daughters toward their mothers change as the girls mature and come to realize that their mothers arent so different after all. As children  the daughters in this book are ashamed of their mothers and dont take them very seriously  dismissing them as quirky and odd. I could never tell my father . . . How could I tell him my mother was crazy? (p. 117). They dont try to comprehend their culture  which is a big part of understanding their traditional Chinese mothers. On page 6  one of the daughters states  I can never remember things I dont understand in the first place  referring to Chinese expressions her mother used. When their mothers show pride in them  the girls only show their embarrassment. One daughter shows her shame when she says to her mother  I wish you wouldnt do that  telling everyone Im your daughter (p. 101). The girls cannot relate to their mothers because they were raised in a different world. No matter how much the mothers care for them or how much they sacrifice to make their girls lives better  the daughters are blind to their mothers pain and feelings. All four of the Joy Luck mothers need their daughters to understand them  pass on their spirit after they are gone  and understand what they have gone through for their girls. One mother dreams of doing this on her trip to a new life: In America I will have a daughter just like me . . . over there nobody will look down on her . . . and she will always be too full to swallow any sorrow! She will know my meaning because I will give her this swan . . . it carries with it all my good intentions (pp. 3-4). Another mother plans how she will give her daughter this perception: She [my daughter] has no chi . . . How can I leave the world without leaving her my spirit? So this is what I will do. I will gather together my past and . . . see a thing that has already happened. The pain that cut my spirit loose. I will hold that pain in my hand until it becomes hard and shiny  more clear. And then my fierceness can come back . . . I will use this sharp pain to penetrate my daughters tough skin and cut her tiger spirit loose. She will fight me  because this is the nature of two tigers. But I will win and give her my spirit because this is why a mother loves a daughter. (p. 286) Things dont exactly turn out the way the mothers hope  though. Their hopes and dreams are shattered when they realize their daughters misconceptions of them. On page 282  a mother laments  When my daughter looks at me  she sees a small  old lady. If she had chuming [inside knowledge of things] she would see a tiger lady. One daughter sees the fear of the remaining mothers after she tells them that she doesnt know anything about her dead mother that she can pass on: They are frightened. In me  they see their own daughters  just as ignorant  just as unmindful of all the truths and hopes they have brought to America. They see daughters who grow impatient when their mothers talk in Chinese  who think they are stupid when they explain things in fractured English . . . They see daughters who will bear grandchildren born without any connecting hope passed from generation to generation. (p. 31)  This fear does not persist  however. As the daughters mature  the two generations discover that they arent so different after all. One mother says  She puts her face next to mine  side by side  and we look at each other in the mirror . . . these two faces  I think  so much the same! The same happiness  the same sadness  the same good fortune  the same faults (p. 292). One daughter  after her mothers death  sits down to play the piano that she had refused to touch before to defy her mother. Amy Tan uses the metaphor of two piano pieces to compare the mother to this daughter: The piece I had played for the recital . . . was on the left-hand side of the page . . . and for the first time . . . I noticed the piece on the right-hand side . . . It had a lighter melody but the same flowing rhythm [as the recital piece and] . . . was longer but faster. And after I played them both . . . I realized they were two halves of the same song (p. 155). The daughters  as they grow to be adults  become more appreciative of their mothers. Their attitudes change over time to create an understanding and respect that hadnt been there before: I saw what I had been fighting for. It was for me  a scared child  who had run away a long time ago to what I had imagined was a safer place. And hiding in this place  behind my invisible barriers  I knew what lay on the other side: her side attacks. Her secret weapons. Her uncanny ability to find my weakest spots. But in the brief instant that I had peered over the barriers I could finally see what was really there: an old woman  a wok for her armor  a knitting needle for her sword  getting a little crabby as she waited patiently for her daughter to invite her in. (pp. 203-204) In conclusion  as children  the daughters didnt understand their mothers or their culture. The daughters were being raised in a different world. Their perceptions of their mothers changed  though  as they grew up and realized that they werent so different from them after all. They finally understood and respected their traditional Chinese mothers.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Do you have a favorite place to goÃ¢â‚¬â€a place with family  good weather  and fun things to do like crabbing? Im glad I do. New Jersey is my favorite place for many reasons. The first reason is my family. Over half of my family lives in New Jersey. When I visit  my cousins and I laugh and play all day and night. My uncles and aunts take me to the boardwalk where we ride roller coasters. We devour juicy caramel-covered apples and foot-long hot dogs. My family is fun to be with. The second reason for New Jersey being my favorite place is the weather. Instead of being hot and sweaty  its always cool and moist. When I think about my visits  I can just feel the crisp fall breeze in my hair. I can just see the white  fluffy winter snow. I can just hear the soft spring trickles of rain splashing on the sidewalks. I can just feel the warm summer sun on my face. The weather is great! The third reason for New Jersey being my favorite place is crabbing. If its crab season  we crab. We keep the blue crabs and the snow crabs  and we let the others go. Sometimes we catch crabs on hooks  and sometimes we lower crab cages into the bay. Then we pull them out later. One time my brother caught a crab so big that it got stuck in the crab cage! The crab finally got out  but it hurt one of its legs and broke the cage trying. Poor crab! For all these reasons  New Jersey is my favorite place to go. If you dont have a favorite place  I think you should search for one. Its good to visit a favorite placeÃ¢â‚¬â€a place where you can make special memories. By the way  if you crab at your special place  be sure to get a big crab cage.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Eyuuuuuuuuu! Nasty! This book was very gross at the beginning because the bullies made a bet with Tom. The bet was for Tom to eat fifteen worms for 50 dollars. What brought me in to the story was the lead which was Hey Tom where were you last night? As I got further into the story it kind of made me want to try a worm Ã¢â‚¬Ëœcause in the fifth and sixth chapter it says  The worms were okay. During the eighth and ninth chapter Tom got a very bad stomach ache from all those worms. Tom didnt only lose 50 dollars he lost energy from those worms because when he got the stomach ache he couldnt do anything. How he lost is he missed his worm. When Toms mom learned about the bet she punished him by sending him to his room till dinner. The author included lots of detail. It made really wonderful pictures in my mind from the long and descriptive words that the author used. I think the author wrote this book to tell us not to bet. It is a bad thing to bet because it can hurt your body. I recommend this book for readers who like adventures and interesting stories.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Fine arts are important in the curriculum because of what they do for learning  stated Patty Taylor  arts consultant for the California State Department of Education. In other words  the arts  especially music  should be part of every schools curriculum at every grade level. Music makes students smarter  gives children something positive to do  and builds self-confidence. Most students dont have a chance to learn music outside of school  and everyone deserves that opportunity. Students would be much smarter if they had some music experience. They would improve their classroom skills  like paying attention  following directions  and participating without interrupting. People develop all these skills when they learn music. Musicians are also better in math  and they get higher S.A.T. scores. For instance  a study by the College Entrance Examination Board reported  Students with 20 units of arts and music scored 128 points higher on the S.A.T. verbal and 118 points higher in math. A Rockefeller Foundation study states that music majors have the highest rate of admittance to medical school. Making music also lets children use their imaginations  unlike playing with video games and electronic stuffed animals. It provides students a chance to try out their own ideas  according to the California Educator. Music makes children well-rounded students. Music not only makes children better students but also gives them something positive to do. In a music program  children can be part of a band or choir instead of getting into trouble. Parents can enjoy listening to their childrens music instead of seeing them glued to a computer or TV screen. In band  students get to be part of a team. They can interact with old friends and make new friends through music. In fact  on her Web site The Musicians Brain  Lois Svard explains how music stimulates mirror neurons  which synchronize performers but also help them empathize with each other. As the great choral conductor Eric Whitacre said  directing a choir is all about getting a room of people to breathe together. In many ways  music helps people connect. Music builds self-confidence. It gives children a sense of accomplishment and success. Making music is something for them to be proud of  and it lets kids practice performing in front of an audience. As reported in the California Educator  It gives [students] self-confidence and a feeling of importance to have a skill someone appreciates. They are also learning how to accomplish something from beginning to end and actually come out with a product that they can be proud of. Music gives children an outlet for self-expression  and that helps develop their self-confidence. Once again  music is important because it can make children better students  give them something positive to do  and build their character. Unfortunately  the children who need music lessons the most usually dont have access to them outside of school. That is why music should be offered in every single grade in every school.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Chores are boring! Scrubbing toilets  cleaning sinks  and washing bathtubs take up a lot of my time and are not fun at all. Toilets! When youre scrubbing toilets make sure they are not stinky. Ive scrubbed one before and I was lucky it didnt stink. I think toilets are one of the hardest things to scrub in the bathroom because it is hard to get up around the rim. Sinks are one of the easiest things to clean in the bathroom because they have no rims and they are small. I have cleaned one before and it was pretty easy. Bathtubs  ever washed one? They are big  they are deep  and it is hard to get up around the sides. The bathtub is the hardest  I think  to wash in the bathroom. All chores are boring  especially making my bed. Cleaning my room is OK because I have to organize  and I like organizing. Dusting is the worst: dust  set down  pick up  dust  set down. There are so many things to dust  and its no fun. Chores arent the worst but theyre definitely not the best!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Jean Baptiste de Lamarck and Charles Darwin were both naturalists that had theories about organisms getting helpful variations. Lamarcks theory was called the theory of acquired characteristics and Darwins was called the theory of evolution by natural selection. Lamarck and Darwins theories are the same and different in some ways.    Darwin and Lamarcks theories were very different. Darwin theory said that organisms get helpful variation before changes in the environment. He thought they got the variation by chance at birth. He explained that the reason giraffes had long necks was because some giraffes had a variation which was a longer neck. The giraffes with short necks could only get food on the ground so they had to compete for it so they died. The giraffes with the long necks did not have to compete because they could get the food up high and they survived and passed the long necks onto their young.  Lamarck theory said that organisms got helpful variation after  a change in the environment. He said that giraffes got long necks when the food on the ground ran out. The giraffes needed to eat food and there was food up high so they stretched out their necks. They then passed it on to their young. Their theories are different because Lamarck thought that organisms changed out of need and after a change in the environment and Darwin thought organisms changed by chance when they were born and before there was a change in the environment.    Darwin and Lamarcks theories were very different but they were also very similar. They both thought that organisms changed. They thought these changes could be very useful and could help them survive. The changes could then get passed down to the young. That is how Lamarck and Darwins theories are similar.    Lamarck and Darwins theories are both the same and different in some ways.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Oh my God  I exclaimed  Whats John doing out there? Why is he on his hands and knees  Mom? I looked out the big kitchen window  wondering if my eight year old brother was all right. He was on hands and knees in our back yard looking rather distressed. Then he threw up. I ran out to see what happened. John stood up and smiled. I was panicked. You have to come inside now! What happened?! I asked  almost screaming. I ate too much at breakfast. I want to keep playing. Im not sick  Ellie! He pouted at me for the next five minutes until agreeing to come inside with me or  as I threatened  mom would be mad. The minute we got inside he started acting like an angel. Little brat. I thought. I hate him. This typical incident was just yesterday  but I can still remember the morning of March 2nd 1969  a day that has affected my life more than I ever could have suspected. To me  a five year old girl  it seemed pretty simple: Mom was having a baby. I couldnt comprehend the implications this would have on my life. When I woke up that morning I went downstairs to demand breakfast  but  instead  grandma was there  and said bluntly  Your moms at the hospital having the baby. Oh  I thought  completely unaffected. I called my friend  Jakie  who lived across the yard  to come over and play. Jakie was my best friend  and she flipped out wondering about the baby and what was going on. Then I started to get curious about it too. My sister  who had already gone through the birth of a younger sibling (me!)  seemed less than enthusiastic. I started to miss my mom  something that had rarely happened before. When Coral  my mom and Dads closest friend  pulled up in our driveway  everyone told me that we were going to the hospital to see my mom and my new brother. I felt my first pangs of jealousy. We all ran to see my mom  who had been in labor all night. I jumped right into the bed next to my exhausted mother as soon as we got into her room. My brother was being weighed and measured  but we got to hold him soon. I was secretly scared because he was so small and delicate. He looked sort of gross  but everyone else seemed to love him  so I didnt say anything. You could barely see his face because of all the wrinkles. Gross! I thought in disgust! His whole body was covered in wrinkles  and he was on the redish side. We decided to call him John Jordan Strosahl. John (now Johnny-Jordan) grew up to be a superbly cute baby Ã¢â‚¬â€ to my disappointment. He had golden blonde baby curls spilling off his head which reminded me of the foam on a coke. Big  round  sapphire eyes lit up his face Ã¢â‚¬â€ as if he need it with such a great big  gummy smile. Thats what has bugged me most for all these years. Frankly  John was the cutest baby  and I knew that the amount of doting time we got wasnt equal; this made me pretty mad.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>9.0</td>\n",
              "      <td>As I step out of the pick-up it hits me  the smell of manure drifting down from the barn. A sliding glass door swishes open  and clomping down the ramp is my boss  Robert Taylor. Put your lunch in the van  Steve. Ill be there in a minute. I turn and walk toward the van  an old 69 green and white Dodge Sportsman  covered with an inch of dust. When I open the door and peer in  it reminds me of a walk-in trash can. The floor lies out of sight underneath a sea of garbage. I kick some garbage out of my way and hop up in the seat. Before long  here comes Rob  clomping across the driveway. He opens the door  groans as he gets up into his seat  cranks the motor over  and the motor sputters to a start  filling the air inside the van with the smell of burnt oil. My first impression is that we wont make it out of the driveway  but we sputter out onto the road  and head toward town. When we pull into the circular drive  I peer through the dust-smudged window to find that the tractor is still there. On the side it reads Massey-Ferguson  but with Robert  its hard telling what it really is. As I sit down in the seat I adjust the hunk of foam rubber to a comfortable position. Once I have accomplished this  I sit down and start cranking on the prehistoric starter. Slowly  and then more rapidly  like a steam engine building up speed  the black smoke rolls out of the pipe functioning as a muffler and away we go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Right now I want you to pretend you are in a store. As you walk around  you see that some products are much less expensive than others. Now  look at the labels on these cheaper items. You will probably notice that many of these labels say  Made in China  or Made in Honduras. Have you ever stopped to wonder why products made in these countries are so much more affordable than things manufactured right here on American soil? Well  before you buy another inexpensive article of clothing  pair of shoes  sporting good  carpet  or any other product  you might want to think this through. Child labor has long been banned in America  but out of sight should not mean out of mind. Over 200 million children world-wide work full time in conditions not fit for an animal. That means that they do not play sports  they do not attend school  and they do not have fun. These children are prisoners. Take  for example  Pakistan and India. In these countries  a bonded labor system forces child laborers  some as young as four years old  to work for a single employer for many years. They are sometimes literally tied to their loom to ensure they are not slacking off. In return for their servitude  they receive a place to sleep and just enough food to sustain them. In Honduras  13% of the workforce is between 12 and 15 years old. There are no laws restricting the ages of the employees  nor are there any limits on the hours they can work. It is not uncommon for a 13 year old child to put in a 14 hour day with no break. However  Honduran employers are required to have a night school for their young laborers to attend. Children put to work weaving carpets  making soap  or any other number of jobs are never paid in full for their toil. Here in the U.S.  the minimum wage is over five dollars an hour. In countries that hire minors to do the dirty work there is almost never a minimum pay requirement. In Haiti  children are  on average  paid 28 cents per hour. In Sri Lanka  the median is 18 cents. Vietnamese and Chinese children should not expect their wages to exceed 11 cents. These numbers are truly tragic. Before you buy something made in a country that condones the labor of young children who work for pennies just so that you can have a more inexpensive item  please think about the situation you are contributing to.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Grade                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Text\n",
              "73     9.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     She had finally gotten her green belt in Tae Kwando. It was an amazing accomplishment for Kameelah D.  a thin African American girl standing about five feet tall. Only four years before  she was told by a doctor that she would never walk again. It was quite evident that not only would she walk again  but she would also run  jump  kick  and punch. When Kameelah was 11  a routine physical uncovered an abnormal curvature in her spine. It was soon after diagnosed as scoliosis. Kameelah  as well as her family  was devastated. They were told by the doctor that only 10 percent of all children are afflicted by scoliosis  but her family just couldnt believe Kameelah was a part of that 10 percent. Her first surgery was scheduled immediately. The doctor had the difficult task of reconstructing Kameelahs entire spine and then re-situating her organs around it. I had never been in the hospital for anything serious before  and Id never had surgery  either. I was so scared  Kameelah recalls. She was given something to fall asleep for the surgery  so that she would not feel anything. Because this surgery dealt with the vertebrae and nerve connections to the brain  the doctor had to make sure that Kameelah could still move her body parts right. Therefore  she was awakened in the middle of the surgery. They would ask me to move my fingers  then my toes. I could barely comprehend what was going on. It was bright  and things werent very clear. In retrospect  I cant believe that I was awake while my back was split open  and the doctors had their hands in there. The first surgery was successful  but Kameelah would have to return two more times for the doctor to completely fix the problem. It was at the end of the third surgery when things went wrong . . . really wrong. The doctor inserted a metal rod  which happened to be too small  into Kameelahs back. As a result  it compressed some of the nerves in her spine. She was practically paralyzed from the waist down. Im really very sorry but . . . I dont think Kameelah will ever be able to walk again  the doctor informed her parents. But Kameelahs father  James  as well as Kameelah herself  refused to accept that prediction. Her father  a registered nurse  insisted that the doctor put her in physical therapy and try to rehabilitate her. He insisted that he be there  too  along with the therapist  helping to rehabilitate his daughter. But the doctor wouldnt oblige. He said that it was a lost cause  and that he knew that Kameelah could never walk again. I was really scared. I just remember telling Dad  Ã¢â‚¬ËœI have to walk. I have to walk  Dad. And he promised me  he swore to me  that I would walk again. He said just what I needed to hear. James kept his promise. He brought Kameelah home in a wheelchair and worked with her  doing exercises that would have been ridiculously easy for any other person  but that were excruciatingly difficult for Kameelah. After about a year  Kameelah was miraculously able to walk with a walker. In no time  she even got strong enough to get along without the walker. Eventually  she walked confidently  and even ran steadily. Now  at the age of twenty-two  she can execute a flying sidekick with the greatest of ease. Not bad for someone who was told she would never walk again  huh? she jokes.\n",
              "167    9.0  Children  as they become adults  become more appreciative of their parents. In The Joy Luck Club  the attitudes of four daughters toward their mothers change as the girls mature and come to realize that their mothers arent so different after all. As children  the daughters in this book are ashamed of their mothers and dont take them very seriously  dismissing them as quirky and odd. I could never tell my father . . . How could I tell him my mother was crazy? (p. 117). They dont try to comprehend their culture  which is a big part of understanding their traditional Chinese mothers. On page 6  one of the daughters states  I can never remember things I dont understand in the first place  referring to Chinese expressions her mother used. When their mothers show pride in them  the girls only show their embarrassment. One daughter shows her shame when she says to her mother  I wish you wouldnt do that  telling everyone Im your daughter (p. 101). The girls cannot relate to their mothers because they were raised in a different world. No matter how much the mothers care for them or how much they sacrifice to make their girls lives better  the daughters are blind to their mothers pain and feelings. All four of the Joy Luck mothers need their daughters to understand them  pass on their spirit after they are gone  and understand what they have gone through for their girls. One mother dreams of doing this on her trip to a new life: In America I will have a daughter just like me . . . over there nobody will look down on her . . . and she will always be too full to swallow any sorrow! She will know my meaning because I will give her this swan . . . it carries with it all my good intentions (pp. 3-4). Another mother plans how she will give her daughter this perception: She [my daughter] has no chi . . . How can I leave the world without leaving her my spirit? So this is what I will do. I will gather together my past and . . . see a thing that has already happened. The pain that cut my spirit loose. I will hold that pain in my hand until it becomes hard and shiny  more clear. And then my fierceness can come back . . . I will use this sharp pain to penetrate my daughters tough skin and cut her tiger spirit loose. She will fight me  because this is the nature of two tigers. But I will win and give her my spirit because this is why a mother loves a daughter. (p. 286) Things dont exactly turn out the way the mothers hope  though. Their hopes and dreams are shattered when they realize their daughters misconceptions of them. On page 282  a mother laments  When my daughter looks at me  she sees a small  old lady. If she had chuming [inside knowledge of things] she would see a tiger lady. One daughter sees the fear of the remaining mothers after she tells them that she doesnt know anything about her dead mother that she can pass on: They are frightened. In me  they see their own daughters  just as ignorant  just as unmindful of all the truths and hopes they have brought to America. They see daughters who grow impatient when their mothers talk in Chinese  who think they are stupid when they explain things in fractured English . . . They see daughters who will bear grandchildren born without any connecting hope passed from generation to generation. (p. 31)  This fear does not persist  however. As the daughters mature  the two generations discover that they arent so different after all. One mother says  She puts her face next to mine  side by side  and we look at each other in the mirror . . . these two faces  I think  so much the same! The same happiness  the same sadness  the same good fortune  the same faults (p. 292). One daughter  after her mothers death  sits down to play the piano that she had refused to touch before to defy her mother. Amy Tan uses the metaphor of two piano pieces to compare the mother to this daughter: The piece I had played for the recital . . . was on the left-hand side of the page . . . and for the first time . . . I noticed the piece on the right-hand side . . . It had a lighter melody but the same flowing rhythm [as the recital piece and] . . . was longer but faster. And after I played them both . . . I realized they were two halves of the same song (p. 155). The daughters  as they grow to be adults  become more appreciative of their mothers. Their attitudes change over time to create an understanding and respect that hadnt been there before: I saw what I had been fighting for. It was for me  a scared child  who had run away a long time ago to what I had imagined was a safer place. And hiding in this place  behind my invisible barriers  I knew what lay on the other side: her side attacks. Her secret weapons. Her uncanny ability to find my weakest spots. But in the brief instant that I had peered over the barriers I could finally see what was really there: an old woman  a wok for her armor  a knitting needle for her sword  getting a little crabby as she waited patiently for her daughter to invite her in. (pp. 203-204) In conclusion  as children  the daughters didnt understand their mothers or their culture. The daughters were being raised in a different world. Their perceptions of their mothers changed  though  as they grew up and realized that they werent so different from them after all. They finally understood and respected their traditional Chinese mothers.\n",
              "26     4.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Do you have a favorite place to goÃ¢â‚¬â€a place with family  good weather  and fun things to do like crabbing? Im glad I do. New Jersey is my favorite place for many reasons. The first reason is my family. Over half of my family lives in New Jersey. When I visit  my cousins and I laugh and play all day and night. My uncles and aunts take me to the boardwalk where we ride roller coasters. We devour juicy caramel-covered apples and foot-long hot dogs. My family is fun to be with. The second reason for New Jersey being my favorite place is the weather. Instead of being hot and sweaty  its always cool and moist. When I think about my visits  I can just feel the crisp fall breeze in my hair. I can just see the white  fluffy winter snow. I can just hear the soft spring trickles of rain splashing on the sidewalks. I can just feel the warm summer sun on my face. The weather is great! The third reason for New Jersey being my favorite place is crabbing. If its crab season  we crab. We keep the blue crabs and the snow crabs  and we let the others go. Sometimes we catch crabs on hooks  and sometimes we lower crab cages into the bay. Then we pull them out later. One time my brother caught a crab so big that it got stuck in the crab cage! The crab finally got out  but it hurt one of its legs and broke the cage trying. Poor crab! For all these reasons  New Jersey is my favorite place to go. If you dont have a favorite place  I think you should search for one. Its good to visit a favorite placeÃ¢â‚¬â€a place where you can make special memories. By the way  if you crab at your special place  be sure to get a big crab cage.\n",
              "105    3.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Eyuuuuuuuuu! Nasty! This book was very gross at the beginning because the bullies made a bet with Tom. The bet was for Tom to eat fifteen worms for 50 dollars. What brought me in to the story was the lead which was Hey Tom where were you last night? As I got further into the story it kind of made me want to try a worm Ã¢â‚¬Ëœcause in the fifth and sixth chapter it says  The worms were okay. During the eighth and ninth chapter Tom got a very bad stomach ache from all those worms. Tom didnt only lose 50 dollars he lost energy from those worms because when he got the stomach ache he couldnt do anything. How he lost is he missed his worm. When Toms mom learned about the bet she punished him by sending him to his room till dinner. The author included lots of detail. It made really wonderful pictures in my mind from the long and descriptive words that the author used. I think the author wrote this book to tell us not to bet. It is a bad thing to bet because it can hurt your body. I recommend this book for readers who like adventures and interesting stories. \n",
              "53     6.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Fine arts are important in the curriculum because of what they do for learning  stated Patty Taylor  arts consultant for the California State Department of Education. In other words  the arts  especially music  should be part of every schools curriculum at every grade level. Music makes students smarter  gives children something positive to do  and builds self-confidence. Most students dont have a chance to learn music outside of school  and everyone deserves that opportunity. Students would be much smarter if they had some music experience. They would improve their classroom skills  like paying attention  following directions  and participating without interrupting. People develop all these skills when they learn music. Musicians are also better in math  and they get higher S.A.T. scores. For instance  a study by the College Entrance Examination Board reported  Students with 20 units of arts and music scored 128 points higher on the S.A.T. verbal and 118 points higher in math. A Rockefeller Foundation study states that music majors have the highest rate of admittance to medical school. Making music also lets children use their imaginations  unlike playing with video games and electronic stuffed animals. It provides students a chance to try out their own ideas  according to the California Educator. Music makes children well-rounded students. Music not only makes children better students but also gives them something positive to do. In a music program  children can be part of a band or choir instead of getting into trouble. Parents can enjoy listening to their childrens music instead of seeing them glued to a computer or TV screen. In band  students get to be part of a team. They can interact with old friends and make new friends through music. In fact  on her Web site The Musicians Brain  Lois Svard explains how music stimulates mirror neurons  which synchronize performers but also help them empathize with each other. As the great choral conductor Eric Whitacre said  directing a choir is all about getting a room of people to breathe together. In many ways  music helps people connect. Music builds self-confidence. It gives children a sense of accomplishment and success. Making music is something for them to be proud of  and it lets kids practice performing in front of an audience. As reported in the California Educator  It gives [students] self-confidence and a feeling of importance to have a skill someone appreciates. They are also learning how to accomplish something from beginning to end and actually come out with a product that they can be proud of. Music gives children an outlet for self-expression  and that helps develop their self-confidence. Once again  music is important because it can make children better students  give them something positive to do  and build their character. Unfortunately  the children who need music lessons the most usually dont have access to them outside of school. That is why music should be offered in every single grade in every school.\n",
              "..     ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...\n",
              "103    3.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Chores are boring! Scrubbing toilets  cleaning sinks  and washing bathtubs take up a lot of my time and are not fun at all. Toilets! When youre scrubbing toilets make sure they are not stinky. Ive scrubbed one before and I was lucky it didnt stink. I think toilets are one of the hardest things to scrub in the bathroom because it is hard to get up around the rim. Sinks are one of the easiest things to clean in the bathroom because they have no rims and they are small. I have cleaned one before and it was pretty easy. Bathtubs  ever washed one? They are big  they are deep  and it is hard to get up around the sides. The bathtub is the hardest  I think  to wash in the bathroom. All chores are boring  especially making my bed. Cleaning my room is OK because I have to organize  and I like organizing. Dusting is the worst: dust  set down  pick up  dust  set down. There are so many things to dust  and its no fun. Chores arent the worst but theyre definitely not the best! \n",
              "225    7.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Jean Baptiste de Lamarck and Charles Darwin were both naturalists that had theories about organisms getting helpful variations. Lamarcks theory was called the theory of acquired characteristics and Darwins was called the theory of evolution by natural selection. Lamarck and Darwins theories are the same and different in some ways.    Darwin and Lamarcks theories were very different. Darwin theory said that organisms get helpful variation before changes in the environment. He thought they got the variation by chance at birth. He explained that the reason giraffes had long necks was because some giraffes had a variation which was a longer neck. The giraffes with short necks could only get food on the ground so they had to compete for it so they died. The giraffes with the long necks did not have to compete because they could get the food up high and they survived and passed the long necks onto their young.  Lamarck theory said that organisms got helpful variation after  a change in the environment. He said that giraffes got long necks when the food on the ground ran out. The giraffes needed to eat food and there was food up high so they stretched out their necks. They then passed it on to their young. Their theories are different because Lamarck thought that organisms changed out of need and after a change in the environment and Darwin thought organisms changed by chance when they were born and before there was a change in the environment.    Darwin and Lamarcks theories were very different but they were also very similar. They both thought that organisms changed. They thought these changes could be very useful and could help them survive. The changes could then get passed down to the young. That is how Lamarck and Darwins theories are similar.    Lamarck and Darwins theories are both the same and different in some ways.  \n",
              "127    6.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Oh my God  I exclaimed  Whats John doing out there? Why is he on his hands and knees  Mom? I looked out the big kitchen window  wondering if my eight year old brother was all right. He was on hands and knees in our back yard looking rather distressed. Then he threw up. I ran out to see what happened. John stood up and smiled. I was panicked. You have to come inside now! What happened?! I asked  almost screaming. I ate too much at breakfast. I want to keep playing. Im not sick  Ellie! He pouted at me for the next five minutes until agreeing to come inside with me or  as I threatened  mom would be mad. The minute we got inside he started acting like an angel. Little brat. I thought. I hate him. This typical incident was just yesterday  but I can still remember the morning of March 2nd 1969  a day that has affected my life more than I ever could have suspected. To me  a five year old girl  it seemed pretty simple: Mom was having a baby. I couldnt comprehend the implications this would have on my life. When I woke up that morning I went downstairs to demand breakfast  but  instead  grandma was there  and said bluntly  Your moms at the hospital having the baby. Oh  I thought  completely unaffected. I called my friend  Jakie  who lived across the yard  to come over and play. Jakie was my best friend  and she flipped out wondering about the baby and what was going on. Then I started to get curious about it too. My sister  who had already gone through the birth of a younger sibling (me!)  seemed less than enthusiastic. I started to miss my mom  something that had rarely happened before. When Coral  my mom and Dads closest friend  pulled up in our driveway  everyone told me that we were going to the hospital to see my mom and my new brother. I felt my first pangs of jealousy. We all ran to see my mom  who had been in labor all night. I jumped right into the bed next to my exhausted mother as soon as we got into her room. My brother was being weighed and measured  but we got to hold him soon. I was secretly scared because he was so small and delicate. He looked sort of gross  but everyone else seemed to love him  so I didnt say anything. You could barely see his face because of all the wrinkles. Gross! I thought in disgust! His whole body was covered in wrinkles  and he was on the redish side. We decided to call him John Jordan Strosahl. John (now Johnny-Jordan) grew up to be a superbly cute baby Ã¢â‚¬â€ to my disappointment. He had golden blonde baby curls spilling off his head which reminded me of the foam on a coke. Big  round  sapphire eyes lit up his face Ã¢â‚¬â€ as if he need it with such a great big  gummy smile. Thats what has bugged me most for all these years. Frankly  John was the cutest baby  and I knew that the amount of doting time we got wasnt equal; this made me pretty mad.\n",
              "143    9.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             As I step out of the pick-up it hits me  the smell of manure drifting down from the barn. A sliding glass door swishes open  and clomping down the ramp is my boss  Robert Taylor. Put your lunch in the van  Steve. Ill be there in a minute. I turn and walk toward the van  an old 69 green and white Dodge Sportsman  covered with an inch of dust. When I open the door and peer in  it reminds me of a walk-in trash can. The floor lies out of sight underneath a sea of garbage. I kick some garbage out of my way and hop up in the seat. Before long  here comes Rob  clomping across the driveway. He opens the door  groans as he gets up into his seat  cranks the motor over  and the motor sputters to a start  filling the air inside the van with the smell of burnt oil. My first impression is that we wont make it out of the driveway  but we sputter out onto the road  and head toward town. When we pull into the circular drive  I peer through the dust-smudged window to find that the tractor is still there. On the side it reads Massey-Ferguson  but with Robert  its hard telling what it really is. As I sit down in the seat I adjust the hunk of foam rubber to a comfortable position. Once I have accomplished this  I sit down and start cranking on the prehistoric starter. Slowly  and then more rapidly  like a steam engine building up speed  the black smoke rolls out of the pipe functioning as a muffler and away we go.\n",
              "135    6.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Right now I want you to pretend you are in a store. As you walk around  you see that some products are much less expensive than others. Now  look at the labels on these cheaper items. You will probably notice that many of these labels say  Made in China  or Made in Honduras. Have you ever stopped to wonder why products made in these countries are so much more affordable than things manufactured right here on American soil? Well  before you buy another inexpensive article of clothing  pair of shoes  sporting good  carpet  or any other product  you might want to think this through. Child labor has long been banned in America  but out of sight should not mean out of mind. Over 200 million children world-wide work full time in conditions not fit for an animal. That means that they do not play sports  they do not attend school  and they do not have fun. These children are prisoners. Take  for example  Pakistan and India. In these countries  a bonded labor system forces child laborers  some as young as four years old  to work for a single employer for many years. They are sometimes literally tied to their loom to ensure they are not slacking off. In return for their servitude  they receive a place to sleep and just enough food to sustain them. In Honduras  13% of the workforce is between 12 and 15 years old. There are no laws restricting the ages of the employees  nor are there any limits on the hours they can work. It is not uncommon for a 13 year old child to put in a 14 hour day with no break. However  Honduran employers are required to have a night school for their young laborers to attend. Children put to work weaving carpets  making soap  or any other number of jobs are never paid in full for their toil. Here in the U.S.  the minimum wage is over five dollars an hour. In countries that hire minors to do the dirty work there is almost never a minimum pay requirement. In Haiti  children are  on average  paid 28 cents per hour. In Sri Lanka  the median is 18 cents. Vietnamese and Chinese children should not expect their wages to exceed 11 cents. These numbers are truly tragic. Before you buy something made in a country that condones the labor of young children who work for pennies just so that you can have a more inexpensive item  please think about the situation you are contributing to.\n",
              "\n",
              "[67 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty_0VpL3vUmW",
        "outputId": "0f135d04-9174-4e3f-d423-2d994aa43e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "separate_sentences(test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>She had finally gotten her green belt in Tae Kwando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>It was an amazing accomplishment for Kameelah D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>a thin African American girl standing about five feet tall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Only four years before  she was told by a doctor that she would never walk again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.0</td>\n",
              "      <td>It was quite evident that not only would she walk again  but she would also run  jump  kick  and punch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>6.0</td>\n",
              "      <td>In Haiti  children are  on average  paid 28 cents per hour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2154</th>\n",
              "      <td>6.0</td>\n",
              "      <td>In Sri Lanka  the median is 18 cents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2155</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Vietnamese and Chinese children should not expect their wages to exceed 11 cents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2156</th>\n",
              "      <td>6.0</td>\n",
              "      <td>These numbers are truly tragic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2157</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Before you buy something made in a country that condones the labor of young children who work for pennies just so that you can have a more inexpensive item  please think about the situation you are contributing to</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2158 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Grade                                                                                                                                                                                                                    Text\n",
              "0       9.0                                                                                                                                                                     She had finally gotten her green belt in Tae Kwando\n",
              "1       9.0                                                                                                                                                                         It was an amazing accomplishment for Kameelah D\n",
              "2       9.0                                                                                                                                                              a thin African American girl standing about five feet tall\n",
              "3       9.0                                                                                                                                        Only four years before  she was told by a doctor that she would never walk again\n",
              "4       9.0                                                                                                                  It was quite evident that not only would she walk again  but she would also run  jump  kick  and punch\n",
              "...     ...                                                                                                                                                                                                                     ...\n",
              "2153    6.0                                                                                                                                                              In Haiti  children are  on average  paid 28 cents per hour\n",
              "2154    6.0                                                                                                                                                                                    In Sri Lanka  the median is 18 cents\n",
              "2155    6.0                                                                                                                                        Vietnamese and Chinese children should not expect their wages to exceed 11 cents\n",
              "2156    6.0                                                                                                                                                                                          These numbers are truly tragic\n",
              "2157    6.0   Before you buy something made in a country that condones the labor of young children who work for pennies just so that you can have a more inexpensive item  please think about the situation you are contributing to\n",
              "\n",
              "[2158 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "jmybJ95T27Y5",
        "scrolled": false,
        "outputId": "46f5b515-3e07-4ce2-8e32-80df4923c901"
      },
      "source": [
        "X_test = separate_sentences(test)\n",
        "y_test = X_test['Grade']\n",
        "X_test[col] = prepare_text(X_test, sp)[col]\n",
        "filepath = 'model-BiLSTM-MLP-hybrid-sm'\n",
        "model = keras.models.load_model(filepath)\n",
        "yhat = model.predict(X_test[col]).ravel()\n",
        "print('MAE = ', np.sum(np.abs(y_test - yhat))/len(y_test))\n",
        "print('STD of errors: ', np.abs(y_test - yhat).std())\n",
        "print('mean grade prediction = ', np.mean(yhat))\n",
        "print('mean grade = ', np.mean(y_test))\n",
        "\n",
        "errors = pd.DataFrame()\n",
        "errors['Text'] = X_test.Text\n",
        "errors['Grade'] = y_test\n",
        "errors['Predicted Grade'] = yhat\n",
        "errors.sample(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE =  1.9245240049742238\n",
            "STD of errors:  1.4518361595284304\n",
            "mean grade prediction =  7.2302694\n",
            "mean grade =  7.314179796107507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Predicted Grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>I reckon theyre goin fer the stairs</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.055093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>He was the only guest of the day, there to promote and discuss his book entitled A Million Little Pieces</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.340609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>When its winter   take buckets of snow and melt it</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.966144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>A hero helps</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.486671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>call into question peopleâ€™s ability to relay information truthfully and with no bias</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.991486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                           Text  ...  Predicted Grade\n",
              "997                                                                         I reckon theyre goin fer the stairs  ...         7.055093\n",
              "694    He was the only guest of the day, there to promote and discuss his book entitled A Million Little Pieces  ...         8.340609\n",
              "588                                                          When its winter   take buckets of snow and melt it  ...         5.966144\n",
              "1841                                                                                               A hero helps  ...         5.486671\n",
              "723                        call into question peopleâ€™s ability to relay information truthfully and with no bias  ...        10.991486\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xEqcrsY27Y6"
      },
      "source": [
        "# Sentence Average Grade Approach\n",
        "\n",
        "In order to create more data to train on we split samples into individual sentences while retaining the original grade label for each one.  New texts then will also be broken down into sentences, individual predictions are made on each sentence, and the model returns the mean average grade level prediction over all sentences. \n",
        "\n",
        "This approach was to combat previous bias in our models toward longer texts being higher grades, to create more data, and to reduce the size of input sequences.  Some of the texts are several pages long.  This also somewhat helped the class imbalance because the older students, which we had fewer of, also wrote texts with more sentences.  \n",
        "\n",
        "Finally, it can take advantage of the 'Wisdom of the Crowds' effect to improve the accuracy on longer texts.\n",
        "\n",
        "`predict_grade()` splits the input text into sentences, uses the input model to make predictions on each one, then returns the mean average of the sentences level predictions as the prediction for the entire text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CJQzwJjn27Y6",
        "scrolled": false,
        "outputId": "c98ae69a-3176-42a9-c5f7-1343c9523f74"
      },
      "source": [
        "model = load_model('model-BiLSTM-MLP-hybrid-sm')\n",
        "errors = test[['Text','Grade']].copy().reset_index(drop=True)\n",
        "yhat = predict_grade(model, test.Text, col, sp)\n",
        "errors['average_prediction'] = yhat\n",
        "\n",
        "print('MAE of average sentence predictor is: ', np.sum(np.abs(errors['Grade'] - errors['average_prediction']))/len(errors))\n",
        "errors.sample(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb7a9b7c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb7a9b7c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAE of average sentence predictor is:  2.068960438913374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Grade</th>\n",
              "      <th>average_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>The Great Depression affected the people that lived through it in many ways. The things at I am going to explain are some of the things that affected the people who lived through the Great Depression. Having barely any money was one of the things that affected them. Also having less supplies affected them too. Having to take care of kids too also might have affected the people during the Great Depression.    First   I am going to talk about how having almost no money affected the people. It affected them because they were getting their money by working. Then their jobs were shutting down so their amount of money was shrinking and shrinking. They would do neighborhood favors and jobs but the amount of money they would get was five dollors. They also had to pay a bill for electricity every month. They had to pay for gas if you had a car and their house. That is why having almost no money affected them a lot.     Another reason the Great Depression affected the people was they were having less of the supplies they had. Like some of the people stopped delivery for several things such as milk and ice. They were also using less electricity and selling their cars. Those are some of supplies they had a shortage or had to not use as much.     Also if they had kids they would need to do extra work and be able to care for them. They also had to pay more money if they had kids because they have to feed them too. They also had to take care of them. The parents have to care for them. If they are sick they can not just leave them at home they have to take care of them. They also might worry about them. If you had kids during the Great Depression not only would you worry about your kids and family. That is why if you had kids during the Great Depression it might be more difficult.     Now you can see how living through the Great Depression was very difficult and affected many people who lived through it. It affected people in many ways like having no money or having a very little amount of it. Also if you had kids it might have been a little more difficult. They also had to live with less supplies. That is why I think the Great Depression affected the people who lived through it.</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.396696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Its too bad that Mr. Griff is closing the shop   Queen thought to herself. Queen and the three dogs had been pets of Mr. Griff   the owner   but now the shop was going out of business   and Mr. Griff put all the furniture outside his shop so people could look at it.  Queen had to hold a meeting with the dogs. They loved the shop   but they would probably have to go to the pound because Mr. Griff wouldnt be able to feed them with what little money he had. Queen meowed a couple of times   and the dogs came bounding over. First Charlie   then Skip   and then Spot. Queen climbed up to the top of the velvet chair and got right down to the point. You guys are going to have to leave here or go to the pound. What do you want to do?   We wouldnt go to the pound for anything   they chorused.  So I guess youre leaving   Queen said. Queen was trying to hold tears back. She loved the dogs   but she wouldnt be able to come with them. She had a bad leg   and whenever she tried to run   pain would shoot up her leg like a lightning bolt electrocuting someone. Queen would have to go to the pound or be a street catÃ¢â‚¬â€an idea she disliked.   Do you boys have all your toys with you?   Yes   we do.   Are you sure you will be OK without me?  We think so.  Queen followed the boys into the shop so she could hear their barks of goodbye to Mr. Griff. But Mr. Griff was talking to a man. After what seemed like an eternity   the man left with a grin on his face. Mr. Griff also had a grin on his face. My wonderful pets   we will be able to stay in the upstairs apartment because that wonderful man bought the shop from us   but he is letting us stay upstairs still! The dogs jumped for joy   and even though she couldnt jump   Queen started to purr.</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.704593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>When spring is in the air  Most of the flowers care. All the leaves grow on trees  And the people with allergies sneeze. All the boys run out  And their parents shout. We all sing about the day That spring flew into replay.</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.106037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>One sunny day   my mom and I took our kittens for a walk around our house. The kittens were very excited because it was their first time. My kittens names are Flounder and Aerial. Aerial is a girl and Flounder is a boy with a circle on his side. They are both the colors yellow and white.        When we took the kittens outside   we had to be very careful so they would not get loose. Then a car drove by. It scared them and they ran.     Their harnesses got loose and they went into the woods. We went inside to put away the harnesses and the leashes. Then we went back outside to look for them in the woods. We looked left and right   but we couldnt find them. We went back home to make signs to put up that said: LOST KITTENS: yellow and white   call 569-9823. We were very sad.  After a few months   still no one could find them. But   when we were looking for them   the kittens were looking for us! They really wanted to find their way home. The kitten asked a cat named Shadow for help. Shadow said    Your family lives next door   but they are not home they are on vacation. Shadow brought them inside to Theresa. When Theresa saw them   she knew who they lived with. Theresa took care of them until we came home. She called us and said   I have a surprise for you!! I thought that she had found our kittens!   When we went over to her house   we followed her up to the bedroom and saw a cage. When she opened the door   we saw our kittens in it. We were so happy that we went right over and unlocked it. The kittens ran out of the cage and over to us. We took them home and thanked Theresa. We were very happy to see them   and they were happy to see us too!</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.528521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>The Lorax said he cares for the earth. The Lorax spoke for the fish. He said   stop putting your left over gunk in the water   because the humming fish cant hum with gunk in their gills. The Lorax spoke for the trees. He said   stop cutting the trees   because they give us air. The Lorax spoke for the Brown Barbaloots. He said   stop cutting trees   because the Brown Barbaloots eat the fruit on the tees. The Lorax cares for the earth.</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.807680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Text  ...  average_prediction\n",
              "56  The Great Depression affected the people that lived through it in many ways. The things at I am going to explain are some of the things that affected the people who lived through the Great Depression. Having barely any money was one of the things that affected them. Also having less supplies affected them too. Having to take care of kids too also might have affected the people during the Great Depression.    First   I am going to talk about how having almost no money affected the people. It affected them because they were getting their money by working. Then their jobs were shutting down so their amount of money was shrinking and shrinking. They would do neighborhood favors and jobs but the amount of money they would get was five dollors. They also had to pay a bill for electricity every month. They had to pay for gas if you had a car and their house. That is why having almost no money affected them a lot.     Another reason the Great Depression affected the people was they were having less of the supplies they had. Like some of the people stopped delivery for several things such as milk and ice. They were also using less electricity and selling their cars. Those are some of supplies they had a shortage or had to not use as much.     Also if they had kids they would need to do extra work and be able to care for them. They also had to pay more money if they had kids because they have to feed them too. They also had to take care of them. The parents have to care for them. If they are sick they can not just leave them at home they have to take care of them. They also might worry about them. If you had kids during the Great Depression not only would you worry about your kids and family. That is why if you had kids during the Great Depression it might be more difficult.     Now you can see how living through the Great Depression was very difficult and affected many people who lived through it. It affected people in many ways like having no money or having a very little amount of it. Also if you had kids it might have been a little more difficult. They also had to live with less supplies. That is why I think the Great Depression affected the people who lived through it.  ...            6.396696\n",
              "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Its too bad that Mr. Griff is closing the shop   Queen thought to herself. Queen and the three dogs had been pets of Mr. Griff   the owner   but now the shop was going out of business   and Mr. Griff put all the furniture outside his shop so people could look at it.  Queen had to hold a meeting with the dogs. They loved the shop   but they would probably have to go to the pound because Mr. Griff wouldnt be able to feed them with what little money he had. Queen meowed a couple of times   and the dogs came bounding over. First Charlie   then Skip   and then Spot. Queen climbed up to the top of the velvet chair and got right down to the point. You guys are going to have to leave here or go to the pound. What do you want to do?   We wouldnt go to the pound for anything   they chorused.  So I guess youre leaving   Queen said. Queen was trying to hold tears back. She loved the dogs   but she wouldnt be able to come with them. She had a bad leg   and whenever she tried to run   pain would shoot up her leg like a lightning bolt electrocuting someone. Queen would have to go to the pound or be a street catÃ¢â‚¬â€an idea she disliked.   Do you boys have all your toys with you?   Yes   we do.   Are you sure you will be OK without me?  We think so.  Queen followed the boys into the shop so she could hear their barks of goodbye to Mr. Griff. But Mr. Griff was talking to a man. After what seemed like an eternity   the man left with a grin on his face. Mr. Griff also had a grin on his face. My wonderful pets   we will be able to stay in the upstairs apartment because that wonderful man bought the shop from us   but he is letting us stay upstairs still! The dogs jumped for joy   and even though she couldnt jump   Queen started to purr.    ...            5.704593\n",
              "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             When spring is in the air  Most of the flowers care. All the leaves grow on trees  And the people with allergies sneeze. All the boys run out  And their parents shout. We all sing about the day That spring flew into replay.  ...            7.106037\n",
              "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        One sunny day   my mom and I took our kittens for a walk around our house. The kittens were very excited because it was their first time. My kittens names are Flounder and Aerial. Aerial is a girl and Flounder is a boy with a circle on his side. They are both the colors yellow and white.        When we took the kittens outside   we had to be very careful so they would not get loose. Then a car drove by. It scared them and they ran.     Their harnesses got loose and they went into the woods. We went inside to put away the harnesses and the leashes. Then we went back outside to look for them in the woods. We looked left and right   but we couldnt find them. We went back home to make signs to put up that said: LOST KITTENS: yellow and white   call 569-9823. We were very sad.  After a few months   still no one could find them. But   when we were looking for them   the kittens were looking for us! They really wanted to find their way home. The kitten asked a cat named Shadow for help. Shadow said    Your family lives next door   but they are not home they are on vacation. Shadow brought them inside to Theresa. When Theresa saw them   she knew who they lived with. Theresa took care of them until we came home. She called us and said   I have a surprise for you!! I thought that she had found our kittens!   When we went over to her house   we followed her up to the bedroom and saw a cage. When she opened the door   we saw our kittens in it. We were so happy that we went right over and unlocked it. The kittens ran out of the cage and over to us. We took them home and thanked Theresa. We were very happy to see them   and they were happy to see us too!  ...            5.528521\n",
              "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The Lorax said he cares for the earth. The Lorax spoke for the fish. He said   stop putting your left over gunk in the water   because the humming fish cant hum with gunk in their gills. The Lorax spoke for the trees. He said   stop cutting the trees   because they give us air. The Lorax spoke for the Brown Barbaloots. He said   stop cutting trees   because the Brown Barbaloots eat the fruit on the tees. The Lorax cares for the earth.  ...            5.807680\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2sIqAqLDKF9"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XI_V5MCC4-k"
      },
      "source": [
        "test[col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvqxGIkyqS9C"
      },
      "source": [
        "The accuracy jumped from 1.8 grade levels average error to 1.4.  In other words, the longer the writing sample, the more accurate the model should be, at least up to a point.\n",
        "\n",
        "Another note here is that while the model takes a long time to load, being almost a 1GB in size, the predictions aren't too slow.\n",
        "\n",
        "# Conclusion\n",
        "With a top accuracy of 1.4 grade levels average error, this model is probably not very useful to a teacher. There are many aspects that go into writing development and the small sample size of our data doesn't give enough.  While dividing texts by sentences raises our sample size from ~300 to ~10,000, there are still only 300 individual writers represented.  The component sentences in a document are going to be highly correlated to the writer and therefor offer less diverse information to the model than if all 10,000 were from independent sources.  \n",
        "\n",
        "~300 is just not enough student writers to find the trends in the noise.  A dataset of 10,000 writing samples from young writers, labeled with their current grade of study, might be enough to return some very interesting insights and much more accurate predictions.  Ideally the writing samples would be selected as representing grade appropriate standards according to the CCSS.  If an accurate predictor could be created that would return the Common Core Standards aligned grade level of a writing, based on writing mechanics.\n",
        "\n",
        "Our baseline model, simply the median of the training set predicted for every text, had an average accuracy of 2.6 grade levels on the validation set.  Traditional machine learning models, linear regression, random forest, and XGBoost improved on that a little by encoding the texts into TF-IDF vectors and fitting on them.  \n",
        "\n",
        "We then tried vectorizing the texts using pre-trained word embedding vectors from the SpaCy large web collected word embedding dictionary.  We used a TextVectorization layer to first encode the words in the text into integers, which the model then used to look up the embeddings in the embedding layer.  This added a dimension to our data before it was passed into a bidirectional Long-Short Term Memory recurrent neural network layer.  The output sequence of that LSTM is flattened and passed through 10 layers of ever shrinking dense layers interspersed with dropout layers for regularization.\n",
        "\n",
        "The output is a regression, not a classification.  It would be simple to make it a classification with rounding, though.  This is essentially what a sigmoid activation on the final layer would do anyway.\n",
        "\n",
        "The model scores significantly better than both the median predictor and any of the shallow models.  While an accuracy of rough one and a half grade levels may not be good enough for use by teachers, it is proof that writing level CAN be predicted, at least to some degree.  \n",
        "\n",
        "# Future Study\n",
        "I recommend more study go into modeling writing development.  The greatest need, from what I could find, is in the collection and anonymization of labeled writing samples from K-12 students.  With a greater library of labeled samples I hypothesize that the model can achieve a precision within one grade level.\n",
        "\n",
        "There are also many more modeling options that can be explored.  I've seen some architectures with convolutional layers.  \n",
        "\n",
        "There are also many more opportunities for text preparation.  NLP is a complex art and tools abound."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1wELyhUqS9C",
        "scrolled": false
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}